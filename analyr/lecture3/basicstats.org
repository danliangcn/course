#+TITLE: 一般统计方法的操作
#+AUTHOR: 厦门大学公共事务学院
#+EMAIL: 
#+OPTIONS: H:2 toc:nil num:t tex:t
#+LATEX_CLASS: beamer
#+COLUMNS: %45ITEM %10BEAMER_env(Env) %10BEAMER_act(Act) %4BEAMER_col(Col) %8BEAMER_opt(Opt)
#+BEAMER_THEME: default
#+BEAMER_COLOR_THEME:
#+BEAMER_FONT_THEME:
#+BEAMER_INNER_THEME:
#+BEAMER_OUTER_THEME:
#+BEAMER_HEADER:
#+LATEX_HEADER: \usepackage{ctex}
#+LATEX_COMPILER: xelatex
#+HTML_HEAD: <style>pre.src {background-color: #303030; color: #e5e5e5;}</style>

* 概率分布  
:PROPERTIES:
:header-args: :results output :exports both :session basicstats
:END:

** 概率基础知识
概率：在随机试验中，某个结果所代表的事件发生的可能性。在实践中经常用频率来近似表示概率。

如果A, B代表可能的结果， \(P(\bar{A}) = 1 – P(A)\).  
如果A和B是截然不同的结果（不重叠），那么 \(P(A\cup B) = P(A) + P(B)\). 

存在条件概率： \(P(A \cap B) = P(A)P(B|A)\). 
如果A和B独立，则 \(P(B|A) = P(B)\) ，那么有 \(P(A \cap B) = P(A)P(B)\) .

*2008 美国GSS数据*
| 收入     | 很幸福 | 一般 | 不幸福 | 总计 |
|----------+--------+------+--------+------|
| 高于平均 |    164 |  233 |     26 |  423 |
| 平均     |    293 |  473 |    117 |  883 |
| 低于平均 |    132 |  383 |    172 |  687 |
| 总计     |    589 | 1089 |    315 | 1993 |
A = 高于平均收入，B = 很幸福  

P(A) = 423/1993 = 0.212 (边际概率)，P(not A) = 1 – P(A) = 0.788  

P(B) = 589/1993 = 0.296  

P(B|A) = 164/423 = 0.388 (条件概率)  

P(A \cap B) = P(A)P(B | A) = 0.212(0.388) = 0.082 (等于 164/1993，联合概率)  

A和B独立吗？

** 频数表与列联表
*** 频数表
#+BEGIN_SRC R :results value
  library(vcd)

  attach(Arthritis)
  table(Improved)
#+END_SRC

#+RESULTS:
| None   | 42 |
| Some   | 14 |
| Marked | 28 |

*** 列联表
#+BEGIN_SRC R
my <- table(Treatment,Improved)
my
#+END_SRC

#+RESULTS:

*** 转化为比例（概率、条件概率）
#+BEGIN_SRC R
prop.table(my)
# 行条件概率
prop.table(my,1)
# 列条件概率
prop.table(my,2)
#+END_SRC

** 频数表与列联表
*** 添加边际频数
#+BEGIN_SRC R 
addmargins(my)
# 添加行（列）边际频数
addmargins(my,1)
addmargins(my,2)
#+END_SRC
*** 添加边际概率
#+BEGIN_SRC R 
addmargins(prop.table(my))
#+END_SRC

*** 列联表的另一种方法
#+BEGIN_SRC R 
xtabs(~Treatment+Improved)
#+END_SRC
** 变量的概率分布
概率分布指随机变量可能的结果（或结果区间）及其概率

*** 离散型变量

P(y) 表示变量 y 的可能结果和概率
\[0\leq P(y) \leq 1, \sum P(y)=1\]

*** 连续型变量 
连续型变量的概率分布是取值区间的分配概率。
正态分布：
+ 对称，钟形
+ 以均值 \mu 和标准差 \sigma 为中心趋势和分散程度特征
+ 对于所有的正态分布，在 \mu 的任一个特定数值的标准差内的概率是相同的。（68-95-99.7法则）
#+BEGIN_SRC R :results output graphics :file 1.png
par(mar=c(4,4,0.1,0.1))
curve(dnorm,-4,4,yaxs='i')
polygon(c(1,seq(1,4,0.1),4),c(0,dnorm(seq(1,4,0.1)),0),col = "red")
#+END_SRC

** 正态曲线尾部概率表
尾部概率：大于 $\mu + z\sigma$ 的值出现的概率，或距离均值超过z个标准差的值出现的概率  

z的第二个小数点位
            
|   z |   .00 |   .01 |   .02 |   .03 |   .04 |   .05 |   .06 |   .07 |   .08 |   .09 |
|-----+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------|
| 0.0 | .5000 | .4960 | .4920 | .4880 | .4840 | .4801 | .4761 | .4721 | .4681 | .4641 |
| ... |       |       |       |       |       |       |       |       |       |       |
| 1.4 | .0808 | .0793 | .0778 | .0764 | .0749 | .0735 | .0722 | .0708 | .0694 | .0681 |
| 1.5 | .0668 | .0655 | .0643 | .0630 | .0618 | .0606 | .0594 | .0582 | .0571 | .0559 |

问题： 落在区间 µ - 1.50σ 到  µ + 1.50σ 的概率是多少？ 0.072右尾概率对应的z值是多少？  
**从概率到z值，从z值到概率的变换，要理解清晰，熟练掌握。**

** z分数（z-scores）和标准正态分布
+ 变量值y的z分数是y离开均值的标准差数: $z = (观测值-均值)/ 标准差 = (y - \mu )/\sigma$      
例子:    y = 65, µ = 50, σ = 10 $z = (y - \mu)/\sigma = (65 – 50)/10 = 1.5$  

+ 标准正态分布是均值 µ = 0, 标准差 σ = 1的正态分布  

+ z分数和标准正态分布：如果一个变量服从一个正态分布，并且其值通过减去均值和除以标准差被转换为z分数，则z分数服从标准正态分布。
#+BEGIN_SRC R
options(digits = 3)
pnorm(65, mean=50, sd=10, lower.tail = FALSE)
pnorm(c(-1.5,1.5))
qnorm(0.072)*(-1)
#+END_SRC
** 抽样分布
抽样分布：抽样分布展现一个统计量（平均值、标准差等）的可以取的值，以及这些值的概率。

例子：y = 1 如果同意房地产限购政策；y = 0 如果反对

假设样本容量n = 3（注意：抽样次数的区别），考虑样本均值  

| 样本      | 均值 | 样本      | 均值 |
|-----------+------+-----------+------|
| (1, 1, 1) | 1.0  | (1, 0, 0) | 1/3  |
| (1, 1, 0) | 2/3  | (0, 1, 0) | 1/3  |
| (1, 0, 1) | 2/3  | (0, 0, 1) | 1/3  |
| (0, 1, 1) | 2/3  | (0, 0, 0) | 0    |

** 样本均值的抽样分布  

+ 样本均值 \(\bar y\) 的值随样本的改变而改变，是围绕总体均值 \mu 波动的变量。  
+  \(\bar y\)的抽样分布的标准差被称为 \(\bar y\)的标准误（standard error）。      
+ 假定从均值 \mu 和标准差 \sigma 的一个总体中抽取容量为n的一个随机样本。 \(\bar y\) 的抽样分布给出 \(\bar y\)的可能值的概率。它的均值为 \mu ，标准误为:  
\(\sigma_{\bar y}=\frac{\sigma}{\sqrt n}=\frac{总体标准差}{\sqrt{样本容量}}\)   
+ 实践的意义：在实际研究中，关于相同主题的研究，由于不同的样本，也可能导致研究结果的不同。
** 中心极限定理
中心极限定理：对于大样本量n的随机抽样，样本均值 \(\bar y\) 的抽样分布是一个近似的正态分布  。

+ 抽样分布的近似正态适用于总体分布的任何形态。
+ 在抽样分布是钟形分布之前n必须有多大，这很大程度上取决于总体分布的偏斜程度。
+ 通过重复选取随机样本，对每个n个观测值的样本计算 \(\bar y\)，可以从经验上验证中心极限定理。
+ 中心极限定理意味着：当一个变量是许多个别因素产生的平均结果（没有主导因素）的时候，那么这个变量的分布是接近正态的（例如智商、血压）。
+ 实践中，我们并不知道总体均值 \mu ，但是我们能够采用抽样分布的离散情况来作为推断未知参数的基础。
#+BEGIN_SRC R :results output graphics :file 2.png 
par(mar=c(3,4,0.1,0.1),mfrow=c(4,4))
set.seed(1234)
n <- c(2,10,30)
curve(dunif,-0.1,1.1,yaxs='i',ylim=c(0,1.5),xlab = "",ylab = "uniform")
samplemean <- NULL
for(k in n){
  for (i in 1:10000){
    samplemean[i] <- mean(runif(k))
  }  
plot(density(samplemean),main = "",xlab = "",ylab = "")
}
plot(c(0,1,2),dbinom(c(0,1,2),2,0.3),type="h",yaxs='i',xlab = "",ylab = "binomial",xlim=c(-0.5,2.5),ylim = c(0,0.6))
samplemean <- NULL
for(k in n){
  for (i in 1:10000){
    samplemean[i] <- mean(rbinom(k,2,0.3))
  }  
  plot(density(samplemean),main = "",xlab = "",ylab = "")
}
curve(dlnorm,0,10,yaxs='i',xlab = "",ylab = "lognorm")
samplemean <- NULL
for(k in n){
  for (i in 1:10000){
    samplemean[i] <- mean(rlnorm(k))
  }  
  plot(density(samplemean),main = "",xlab = "",ylab = "")
}
curve(dnorm,-4,4,yaxs='i',xlab = "",ylab = "normal")
samplemean <- NULL
for(k in n){
  for (i in 1:10000){
    samplemean[i] <- mean(rnorm(k))
  }  
  plot(density(samplemean),main = "",xlab = "",ylab = "")
}
#+END_SRC
由左到右为：总体分布、抽样分布（2）、抽样分布（10）、抽样分布（30）


* 统计推断：估计
:PROPERTIES:
:header-args: :results output :exports both :session estimates
:END:

** 参数估计
+ 目标：如何利用样本数据估计总体参数的值
+ 点估计：是对参数进行最佳推测的一个数值。
+ 区间估计：是以点估计为中心的一个数值区间，参数值被认为落在其中。

** 点估计
+ 利用样本均值估计总体均值 \mu 
\[\hat \mu=\bar y=\frac{\sum y_i}{n}\]

+ 利用样本标准差估计总体标准差 \sigma
\[\hat \sigma=s=\sqrt{\frac{\sum (y_i-\bar y)^2}{n-1}}\]
+ 利用样本比例 \(\hat \pi\) 估计总体比例 \pi

** 好估计量具有的性质
+ *无偏的：* 估计量的抽样分布以参数为中心  
e.g. 有偏的估计量：样本全距
+ *有效的：* 与其他估计量相比，具有尽可能小的标准误  
e.g. 如果总体分布是对称的，并且接近正态，样本均值比样本中位值在估计总体均值和中位值时，更有效

** 置信区间（Confidence Intervals）
+ 参数的置信区间是一个相信参数落在其中的数值区间。
+ 这种方法产生一个包含参数的区间概率称为置信水平。大多数研究采用的接近1的置信水平，例如0.95或者0.99.

+ 置信区间的形式： 
$$点估计 \pm 误差边际$$

+ 误差边际是由点估计的抽样分布的离散程度决定的。

e.g. 构造拥有“95%置信度”的一个置信区间，可用点估计加减约两个标准差的误差边际。

** 比例的置信区间 
+ 当 \(y = 1\) 代表感兴趣类别的一个观测值时， \(y = 0\) 就代表另外的观测值，样本比例 \(\hat \pi\) 是一个均值。

+ 总体比例 \(\pi\) 是下面分布的均值
$$P(1)=\pi \\ P(0)=1-\pi$$

+ 这个概率分布的标准差是：
$$\sigma =\sqrt{\pi (1-\pi )}$$

+ 样本比例 \(\hat \pi\)的标准误是：
$$\sigma_{\hat \pi}=\sigma / \sqrt{n}=\sqrt{\pi (1-\pi ) / n}$$

** 比例的置信区间
+ 对于大的随机样本，样本比例的抽样分布是接近正态的（中心极限定理）

+ 那么，样本比例 $\hat \pi$ 应以0.95的概率落在其均值（总体比 $\pi$）的两个标准差（准确值是1.96）之内。
$$\hat \pi \quad 落在 \quad \pi - 1.96\sigma_{\hat \pi} \quad 和 \quad \pi + 1.96\sigma_{\hat \pi} \quad 之间$$

+ 一旦选取了样本，那么有95%的信心，
$$\hat \pi - 1.96\sigma_{\hat \pi} \quad 到 \quad \hat \pi + 1.96\sigma_{\hat \pi} \quad 之间包含 \quad \pi$$
此即总体比例的置信区间。

+ 由于样本比例的标准误含有未知参数，用估计值代替

$$se=\sqrt{\hat \pi (1- \hat \pi )} \qquad 替代 \qquad  \sigma_{\hat \pi}=\sqrt{\pi (1-\pi ) / n}$$


+ 对 \pi 的95%的置信区间为：
$$\hat \pi - 1.96(se) \qquad 到 \qquad \hat \pi + 1.96(se)$$

** 置信区间的性质
+ 置信区间的宽度随置信水平的增大而增大；随样本量的增大而变小。

+ 置信区间是长期正确的比例.    

+ 区间估计方法产生不包括参数的置信区间的概率被称为错误概率 $\alpha$

+ $\alpha = 1- 置信水平$

| $1-\alpha$ | $\alpha$ | $\alpha /2$ | $Z_{\alpha /2}$ |
|------------+----------+-------------+-----------------|
|        90% |      .10 |        .050 |           1.645 |
|        95% |      .05 |        .025 |            1.96 |
|        99% |      .01 |        .005 |            2.58 |

** 均值的置信区间
+ 对于大的随机样本，样本均值有渐进正态的抽样分布，其均值为\mu，标准误 $\sigma_{\bar y}=\sigma / \sqrt n$ 

+ 相似的，有 $P(\mu-1.96\sigma_{\bar y} \leq \bar{y} \leq \mu+1.96\sigma_{\bar y})=0.95$

+ 有95%的置信度，样本均值落在（未知）总体均值的1.96个标准误的范围内。

+ 标准误是未知的，因此要用样本数据的点估计来代替标准误

$$\bar y \pm 1.96(se), \quad 即 \quad \bar y \pm 1.96\frac{s}{\sqrt n} \qquad se=\frac{s}{\sqrt n}$$

+ 对于较大的样本容量是没有问题的，但是对于较小的样本量，用估计量s替代 \sigma 会造成误差，置信区间会偏小。因此要采用t分数代替z分数。

** t 分布  (Student’s t from W.S. Gosset)
+ t分布是钟形分布并关于均值0对称。

+ 标准差略大于1（比标准正态分布的尾部要厚一些）
具体形状由自由度(df)决定。对于总体均值的推断，自由度为 df = n – 1 

+ 随着自由度df的增加，t分布越接近于标准正态分布，df大于30时，几乎与标准正态分布相同。

+ t分数（代替z分数）乘以估计的标准误，给出了均值的置信区间的误差边际。
#+ATTR_HTML: :width 150
[[./image1.png]]
** 部分 t 分数
*置信水平*  

|        |   90% |    95% |    98% |    99% |
|--------+-------+--------+--------+--------|
|     df | t.050 |  t.025 |  t.010 |  t.005 |
|      1 | 6.314 | 12.706 | 31.821 | 63.657 |
|     10 | 1.812 |  2.228 |  2.764 |  3.169 |
|     16 | 1.746 |  2.120 |  2.583 |  2.921 |
|     30 | 1.697 |  2.042 |  2.457 |  2.750 |
|    100 | 1.660 |  1.984 |  2.364 |  2.626 |
| 无穷大 | 1.645 |  1.960 |  2.326 |  2.576 |

+ df = 无穷大时，和标准正态分布相同。
#+BEGIN_SRC R 
options(digits=4)
qt(0.025, df=10, lower.tail=FALSE)
#+END_SRC

** 总体均值的置信区间
+ 对于来自正态总体分布的随机样本，均值 \mu 的95%置信区间为：

$$\bar y \pm t_.025 \times se, \quad 其中 \quad se=s/\sqrt n$$

计算t分数的自由度df = n - 1

+ 正态分布的假定是确保对于任何的n抽样分布都是钟形。

+ *总体均值 \mu 置信区间的性质*  
  + 对均值的置信区间的假定是：使用随机化选择样本；总体分布是正态的。在这两个假定下，样本均值的抽样分布是正态的。用估计的标准误替代未知的真实标准误后，样本均值服从t分布。

  + 在违背正态总体假定时，对均值使用t分布的置信区间是稳健的（robust）。但是，如果样本数据非常偏态或包含极端异常值，方法的稳健性会降低，因此要进行探索性分析。

  + 置信水平越高，那么置信区间就越大；样本容量 n 越大，置信区间越窄。

** 用R计算置信区间
+ 比例的置信区间：1000人的样本中700人选择“YES”，总体比例的95%的置信区间
#+BEGIN_SRC R
y <- 700
n <- 1000
estimate <- y/n
se <- sqrt (estimate*(1-estimate)/n)
int.95 <- estimate + qnorm(c(.025,.975))*se
int.95

#自动计算，默认是95%的置信区间
cinterval <- prop.test(y,n)
cinterval$conf.int
#+END_SRC

+ 均值的置信区间：5个人的年龄组成的样本，总体平均年龄的95%的置信区间
#+BEGIN_SRC R
y <- c(35,34,38,35,37)
n <- length(y)
estimate <- mean(y)
se <- sd(y)/sqrt(n)
int.95 <- estimate + qt(c(.025,.975),n-1)*se
int.95
#自动计算，默认是95%的置信区间
cinterval <- t.test(y)
cinterval$conf.int
#+END_SRC

** 置信区间的含义
+ 置信区间是长期正确的比例：95% 的置信度为有95%的区间会覆盖总体均值 $\mu$
#+BEGIN_SRC R :results output graphics :file 3.png 
# Set the random seed
set.seed(123456)

# initialize vectors to later store results:
CIlower <- numeric(10000); CIupper <- numeric(10000)
pvalue1 <- numeric(10000); pvalue2 <- numeric(10000)

# repeat 10000 times:
for(j in 1:10000) {
  # Draw a sample
  sample <- rnorm(100,10,2)
  # test the (correct) null hypothesis mu=10:
  testres1 <- t.test(sample,mu=10)
  # store CI & p value:
  CIlower[j] <- testres1$conf.int[1]
  CIupper[j] <- testres1$conf.int[2]
  pvalue1[j] <- testres1$p.value
}

# Test results as logical value
reject1<-pvalue1<=0.05

# color vector:
color <- rep(gray(.5),100)
color[reject1[1:100]] <- "black"

# Prepare empty plot with correct axis limits & labels:
plot(0, xlim=c(9,11), ylim=c(1,100), 
                       ylab="Sample No.", xlab="", main="Correct H0")
# Vertical line at 10:
abline(v=10, lty=2)
# Add the 100 first CIs (y is equal to j for both points):
for(j in 1:100) {
  lines(c(CIlower[j],CIupper[j]),c(j,j),col=color[j],lwd=2)
}
#+END_SRC

** 样本量的选择
+ 在估计总体比例时，选取多大的样本量，才能使得置信度为0.95，误差不超过0.03？

  - 可以让 0.03 = 误差边际，然后求 n 的值  

  - $0.03=1.96\sigma_{\hat \pi}=1.96\sqrt{\pi (1-\pi) / n}$

  - $n=\pi (1-\pi)(1.96/0.03)^2=4268\pi (1-\pi)$

  - \pi=0.5 时，n值最大，所以 $n=4268\cdot 0.5\cdot 0.5=1067$
+ 如果从前的研究显示总体均值大概是0.20，95%置信区间的误差边际为0.03的最低样本量为：

$$n=\pi (1-\pi)(1.96/0.03)^2=4268\pi (1-\pi) \\ =4268\cdot 0.2 \cdot 0.8=83$$

+ 总体比例接近0或1的时候，要比总体比例接近0.5更“容易”估计

+ 除非完全不了解总体比例的值，最好是用估计值，而不是0.50计算

** 样本量的选择
+ 确定估计的参数的类别（总体比例或者总体均值）

+ 选择误差边际 (M) 和置信水平 (决定z分数)

+ 比例（如果不知道，可设 $\pi=0.50$）： 

$$n=\pi (1-\pi)(\frac{z}{M})^2$$

+ 均值（需推测总体标准差的值 $\sigma$）： 

$$n=\sigma^2(\frac{z}{M})^2$$

+ 置信区间与样本量：

  - 样本量与置信水平（更高的置信度要求更大的样本量）和总体变异度（变异程度越高要求更大的样本量）相关。

  - 实践中，事先确定样本容量比较难。一是因为许多参数都要估计；二是因为资源有限，需要权衡。

  - 任何参数都可以确定其置信区间。

** 实际使用置信区间时需要考虑的因素

+ 确定感兴趣的变量类型：
  - 定量变量 – 推断均值
  - 类别变量 – 推断比例

+ 检验前提条件是否满足？
  - 随机化 (抽样分布及其标准误)

  - 其他条件？
    
    均值：数据探索性分析检查数据的分布确保均值是一个合适的参数。
    
    比例：类别中的观察个体至少有15个，不在类别中的观察个体也至少15个。


* 统计推断：显著性检验  
:PROPERTIES:
:header-args: :results output :exports both
:END:

** 显著性检验
+ 目的：利用统计方法检验假设

  - “治疗厌食症，采用认知行为家庭疗法与安慰剂产生的平均体重变化相同”  （没有效果）

  - “社会经济地位越高则心理健康程度越高”  （存在效应）

  - “为别人花钱比为自己花钱更幸福”

+ 假设：在统计推断中，对研究所关心的变量，我们会对总体的参数进行某种预测，这种对总体参数的预测便是一个假设。

+ 显著性检验利用样本对参数的点估计与假设预测的参数值之间比较，来评价一个假设。

+ 一般而言我们回答这样一个问题：“如果假设成立，得到现有样本数据的 *不可能性* 有多高？”

** 显著性检验的5个部分
1. 前提假定（Assumptions）：数据类型（定量数据、分类数据）、抽样方式（随机化）、总体分布（正态分布等）、样本量（是否足够大）

2. 假设（Hypotheses）:   
  + 原假设（ $H_0$）：对参数取一个特定值的陈述。(一般是指“没有效果”)
  + 备择假设（ $H_a$）：陈述参数值落在某个备择的值域。（一般指“有效果”）

3. 检验统计量：用来和原假设的预测进行比较。一般通过标准误的个数来测量样本点估计与原假设的参数值之间的距离。

4. P值 (P): 用概率来表现的关于原假设成立与否的证据。在原假设成立的条件下，检验统计量等于观测值及更极端值的概率（备择假设预测的方向）。P值越小，那么反对原假设的证据越强。

5. 结论：   
  + 无需判断的话，只报告p值和进行解释。
  + 如需判断的话，选择一个临界点（显著性水平，例如0.05或者0.01）。如果P值小于等于这个临界点的值，那么就拒绝原假设。

** 均值的显著性检验
+ 前提假定：随机化，定量变量，正态总体分布（稳健性）

+ 原假设： H_0: \mu=\mu_0，其中 \mu_0是总体均值的一个特定的值。
     (通常与某个标准相比没有效果或没有变化)

+ 备择假设： $H_{\alpha}: \mu \neq \mu_0$ 
     双侧备择包括大于和小于原假设值

+ 检验统计量： 样本均值离原假设值的距离，用标准误的个数来衡量。
$$t=\frac{\bar y-\mu_0}{se}, \quad se=s/\sqrt n$$
当原假设 H_0 为真，t统计量的抽样分布是自由度为 df = n – 1 的t分布。

+ P值：原假设为真的假定下，t统计量等于观察值或更极端的取值的概率。
	对于双侧备择假设 H_{\alpha}，那么对应是双尾概率

+ 结论：报告和解释P值，如有需要，还要对原假设H_{0}进行判断。

** 例子：厌食症的治疗
+ y为治疗后与治疗前的体重差值：11.4, 11.0, 5.5, 9.4, 13.6, -2.9, -0.1, 7.4, 21.5, -5.3, -3.8, 13.4, 13.1, 9.0, 3.9, 5.7, 10.7  

*如何证明治疗有效果？*  
+ 设 \mu 为体重变化的总体均值
+ 检验原假设  $H_0: \mu=0$（无效果），相应备择假设 $H_{\alpha}: \mu \neq 0$.
+ 由数据可以得到  

| 变量   | 样本量 |  均值 | 标准差 | 均值标准误 |
|--------+--------+-------+--------+------------|
| 体重差 |     17 | 7.265 |  7.157 |      1.736 |

$$se=s/\sqrt n=7.157/\sqrt {17}=1.736$$

+ 检验统计量（df=16）： $t=\frac{\bar y - \mu_0}{se}=\frac{7.265-0}{1.736}=4.18$

+ P值： $pvalue=2 \times P(t>4.18)=0.0007$（软件计算）说明如果原假设 H_0 为真，那么得到一个距离原假设0值至少4.18个标准误远的样本均值的概率为 0.0007。

+ 结论：非常强的证据显示总体均值不为0. （具体看起来 $\mu >0$）

** 单样本均值的显著性检验
#+BEGIN_SRC R
y <- c(11.4, 11.0, 5.5, 9.4, 13.6, -2.9, -0.1, 7.4, 21.5, -5.3, -3.8, 13.4, 13.1, 9.0, 3.9, 5.7, 10.7)
n <-length(y)
se <- sd(y)/sqrt(n)
t <- (mean(y)-0)/(se)
pvalue <- 2*(1-pt(t,df=16))

t.test(y)
#+END_SRC

** 双侧检验与置信区间之间的对应关系
+ 当双侧检验的 P值 \leq 0.05时，总体均值 \mu 的95%的置信区间不包括原假设 H_0 预测的均值 (例如为0)

+ 上面的例子：P = 0.0007, 95% 的置信区间为  (3.6, 10.9)

+ 当双侧检验的 P值 > 0.05 时，95% 的置信区间必然包括原假设 H_0 预测的均值。

+ 置信区间提供了更多关于总体均值的信息

例子: 假设样本均值为7.265、标准差为 7.16都保持不变，但是样本容量 n = 4    (不是前面的 n = 17)，那么双侧检验的p值为0.14，95%的置信区间为(-4.1, 18.7)，即p值大于显著性水平，相应置信区间包含了0.
** 均值的单侧检验
例子：
如果研究预测到治疗方法有正面效果，可以采用备择假设 H_{\alpha}>0，如果t在右尾部越远，则表明数据越支持这个备择假设，那么此时的P值 = 右尾概率。
+ 假定对于样本 n = 4 (df = 3)，有 t = 2.0，那么 $Pvalue = P(t > 2.0) = 0.07$  
+ 如果备择假设是： $H_{\alpha}: \mu <0$,  P值 = 左尾概率； $Pvalue = P(t < 2.0) = 0.93$  
+ 实践中，双侧检验更普遍。

** 统计决策 

 \alpha 水平是一个选定的数值，被称为显著性水平。 

如果P值 \leq \alpha ，那么拒绝原假设 $H_0$
如果P值 > \alpha ，那么不拒绝原假设 $H_0$ 

注意：表述是“不拒绝 $H_0$” 而不是“接受 $H_0$”，因为原假设 $H_0$  的值仅仅是众多可能取值中的一个。

例子 (n = 4, 双侧): 假定 $\alpha=0.05$. 由于 P值 =  0.14，那么我们不能拒绝原假设 $H_0$.  但是 0 仅仅是95%置信区间 (-4.1, 18.7)的取值中的一个，所以我们只能是不拒绝，不能表述为接受。

** 样本量大小对检验的影响
+ 当样本量 n 比较大时（例如，n > 30），根据中心极限定理，正态总体分布假定变得不重要。

+ 对于小样本量而言，如果正态总体假定不成立，双侧 t 检验是稳健的，然而单侧检验不稳健。

+ 对于给定的观察样本均值和标准差，样本量越大，检验统计量越大（因为分母中的标准误se越小），p值越小

+ 当样本量越大的时候，越可能拒绝一个错误的原假设 $H_0$

+ 当样本量较大时，“统计显著性”不等于是“具有实际意义的显著性”

** 比例的显著性检验
+ 前提假定：类别变量、随机化、大样本（但是小样本做双侧检验也OK）

+ 假设：
  - 原假设: $H_0: \pi=\pi_0$
  - 备择假设: $H_{\alpha}: \pi \neq \pi_0$(双侧)； H_{\alpha}: \pi > \pi_0 或者 $H_{\alpha}: \pi < \pi_0$(单侧)
  - 在得到数据前就要设定好假设

+ 检验统计量

$$z=\frac{\hat \pi-\pi_0}{\sigma_{\hat \pi}}=\frac{\hat \pi-\pi_0}{\sqrt{\pi_0(1-\pi_0)/n}}$$
+ p值：
  -  $H_{\alpha}: \pi \neq \pi_0$ P=标准正态分布双尾概率
  -  $H_{\alpha}: \pi > \pi_0$ P=标准正态分布的右尾概率
  -  $H_{\alpha}: \pi < \pi_0$ P=标准正态分布的左尾概率
  
+ 结论：如果P值小于等于显著性水平，则拒绝原假设 $H_0$

** 例子：狗能闻出膀胱癌吗？(British Medical Journal, 2004)
每次测试，1个膀胱癌尿样放在6个控制尿样中，如何检验狗能否比随机猜测得到更好的结果？

让 $\pi=$ 某次测试猜对的概率。 $H_0: \ \pi-1/7$ (= 0.143, 没有影响),  $H_{\alpha}>1/7$

54次测试，狗能够做出正确的选择22次。样本比例 = 22/54 = 0.407

标准差 $se_0=\sqrt{\pi_0(1-\pi_0)/n}=\sqrt{(1/7)(6/7)/54}=0.0476$

检验统计量： $z=(\hat \pi-\pi_0)/se_0=(0.407-(1/7))/0.0476=5.6$

p值=标准正态分布的右尾概率=0.00000001

因此，有非常强的证据显示狗的选择比随机猜测要更好。

那么对于标准的显著性水平 \alpha 为0.05，我们拒绝原假设 H_0 得到结论 $\pi>1/7$.

** 检验中的决策
+  \alpha 水平（显著性水平）：是一个事先指定的“门槛”，如果P值落在它（一般采用0.05或者0.01）之下，那么拒绝原假设 $H_0$

+ 拒绝域：检验拒绝 H_0 的那些检验统计量值的集合。对于显著性水平 \alpha=0.05 的双侧检验，如果 |z|\geq 1.96 ，那么拒绝 $H_0$

+ 错误类型
  - 第一类型错误：当原假设 H_0 为真时，拒绝原假设  
  
  - 第二类型错误：当原假设 H_0 为假时，不拒绝原假设  
  
  -  \alpha 是第一类错误的概率，选择的 \alpha 越小，则第二类错误发生的概率 \beta 会增加  
  
  - 检验的功效 = 1-\beta = P(原假设为假的条件下拒绝它)

** 正态总体单样本参数假设检验
+ 总体均值的检验（大样本： $n \ge 30$）  
 
\sigma^{2} 已知：
$$ z=\frac{\bar x-\mu_0}{\sigma/\sqrt{n}}\sim N(0,1)$$

 \sigma^{2}未知：
$$ z=\frac{\bar x-\mu_0}{s/\sqrt{n}}\sim N(0,1)$$
+ 总体均值的检验（正态总体小样本）  
 
\sigma^{2}已知：
$$ z=\frac{\bar x-\mu_0}{\sigma/\sqrt{n}}\sim N(0,1)$$

\sigma^{2}未知：
$$ t=\frac{\bar x-\mu_0}{s/\sqrt{n}}\sim t(n-1)$$

** 例子
某汽车生产商声称其生产的汽车每加仑汽油可行驶的里程不低于25英里，标准差为2.4英里。消协组织了一个由10位汽车主组成的小组，他们的汽车每加仑汽油的可行驶英里数如下表。假定汽车每加仑可行驶里程服从正态分布。现在问，汽车生产商的诺言可信吗？

|序号|1|2|3|4|5|6|7|8|9|10|
|--|--|--|--|--|--|--|--|--|--|--|
|里程|22|24|21|24|23|24|23|22|21|25|
+ 此种情况实践中比较少见，只能采用自编函数完成
#+BEGIN_SRC R
options(digits = 2)
u.test<-function(x,mu,thegma)
{  se=thegma/sqrt(length(x))
   u=(mean(x)-mu)/se
   p=pnorm(u)
   c(u=u, p=p)
}
b=c(22,24,21,24,23,24,23,22,21,25)
u.test(b, 25,2.4)

#+END_SRC
** 例子
一位投资者考虑是否选择新的资产管理公司，为使收益最大化，如果新的资产公司平均收益率大于原来资产管理公司的平均收益率，公司将选择新的资产管理公司。原来的资产公司的客户平均收益率为50.0%，对新资产管理公司的客户进行抽样检验，12个客户的收益率如下：50.2%，49.6%，51.0%，50.8%，50.6%，49.8%，51.2%，49.7%，51.5%，50.3%，51.0%和50.6%，假设资产管理公司客户收益率的分布比较近似于正态分布，问新资产管理公司的平均收益率是否大于原来的资产管理公司? 
#+BEGIN_SRC R
x=c(.502,.496,.510,.508,.506,.498,.512,.497,.515,.503,.510,.506)
t.test(x,mu=.500,alternative ="greater") 
#+END_SRC
** 正态总体单样本参数假设检验
+ 总体比例的检验  
 假定条件：
  总体服从二项分布；
  可用正态分布来近似（大样本）。  

   检验的Z统计量：
$$ z=\frac{\hat \pi-\pi_0}{\sqrt{\pi_0(1-\pi_0)/n}}\sim N(0,1)，\pi_0为假设的总体比例. $$

+ 总体方差的检验  
 检验一个总体的方差或标准差，假设总体近似服从正态分布，使用 \chi^2 分布。  
 检验统计量：  
$$ \chi^2=\frac{(n-1)s^2}{\sigma_0^2}\sim \chi^2(n-1)$$

** 总体比例检验示例
为调查某大学男女比率是否是1:1，在校门处观察，发现100学生中有45个女性。那么，这是否支持该大学总体男性占比为50%的假设？
#+BEGIN_SRC R
prop.test(45,100,p=0.5)
#+END_SRC

** 总体方差检验示例
某地区环保部门规定，废水经设备处理后水中某种有毒物质的平均浓度，均值和标准差单位是微克。通过抽查20个废水样品，如何判断水样的标准差是否为20微克？
+ 只能采用自编函数var.test1完成，R里面的var.test函数是用来比较两个对象的。
#+BEGIN_SRC R
var.test1<-function(x, sigma2){
  n<-length(x)
  svar=var(x)
  df=n-1
  chi2<-df*svar/sigma2;
  P<-pchisq(chi2,df)
  data.frame(var=svar, df=df, chisq2=chi2, P_value=P)
}
x=c(512.952899108198, 503.85274864927, 495.06951127009, 477.193305294993, 509.400520346022, 493.249014260413, 492.456674317536, 530.078195416527, 498.757258963417, 522.657000900506, 510.041124496973, 490.505063978937, 536.24855605503, 530.039965979141, 495.559165160148, 466.840695851664, 510.702680801237, 524.485012890925, 490.37616974915, 485.579333872921)
var.test1(x,400)
#+END_SRC
** 正态总体双样本参数假设检验
*** 双样本方差的检验（方差齐性检验）  
 假定条件：
  两个总体都服从正态分布。
  两个独立的随机样本。

   检验统计量：
$$ F=\frac{s_1^2}{s_2^2}\sim F(n_1-1,n_2-1)\ 或 \ F=\frac{s_2^2}{s_1^2}\sim F(n_2-1,n_1-1)$$

** 例子
假设您是一个轮胎生产商，您从两个厂家买入轮轴，假设每个轮轴的直径服从正态分布，请问如何检验两者方差大小？
#+BEGIN_SRC R
x1=c(24, 29, 39, 40, 32, 32, 31, 44, 37, 37, 50, 28, 24, 48, 25, 40, 32, 34, 35, 41)
x2=c(44, 34, 36, 38, 30, 30, 35, 38, 40, 46, 38, 35, 38, 36, 38, 40, 34, 37, 40, 46)
var.test(x1,x2)
#+END_SRC

** 正态总体双样本参数假设检验
*两样本均值检验:*
将一个样本与另一样本均值相比较的检验，分为两独立样本检验和配对样本检验。
*** 两独立样本 t 检验（方差齐性）  
 假定条件：
  两个样本是独立的随机样本。
  两个总体都是正态分布。  
  两个总体的方差 $\sigma_1^2，\sigma_2^2未知但相等，即\sigma_1^2=\sigma_2^2。$  
 检验统计量：

$$t=\frac{(\bar x_1-\bar x_2)-(\mu_1-\mu_2)}{s_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}，其中s_p=\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}，自由度：n_1+n_2-2$$
*** 两独立样本 t 检验（方差不齐时）：
$\sigma_1^2，\sigma_2^2未知且不相等，即\sigma_1^2\ne\sigma_2^2。$
$$t=\frac{(\bar x_1-\bar x_2)-(\mu_1-\mu_2)}{\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}}，自由度：最接近v的整数——v=\frac{(\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2})^2}{\frac{(s_1^2/n_1)^2}{n_1-1}+\frac{(s_2^2/n_2)^2}{n_2-1}}$$

** 例子
一员工对乘当地公交车上班快还是自己开车快的问题产生了兴趣。通过对两种方式所用时间各进行了10次记录，具体数据见下表。设每一种方式的天数是随机选取的，假设乘车时间服从正态分布。这些数据能提供充分的证据说明开车去的平均时间快吗？

| 公交 | 48 | 47 | 44 | 45 | 46 | 47 | 43 | 47 | 42 | 48 |
|------+----+----+----+----+----+----+----+----+----+----|
| 开车 | 36 | 45 | 47 | 38 | 39 | 42 | 36 | 42 | 46 | 35 |

1. 两样本均值检验，需要先验证样本是否服从正态分布（后面介绍），如果已知总体服从正态，样本量较大就不需要。  
1. 判断两个样本是否有相同的方差  
1. t 检验判断均值（t.test默认方差不等）

#+BEGIN_SRC R
x1=c(48,47,44,45,46,47,43,47,42,48)
x2=c(36,45,47,38,39,42,36,42,46,35)
# 方差齐性检验
var.test(x1,x2)
# t 检验判断均值
t.test(x1,x2,var.equal = FALSE)
#+END_SRC

** 正态总体双样本参数假设检验
*** 两配对样本 t 检验 
 假定条件:
 两个总体配对差值构成的总体服从正态分布。
 配对差是由差值总体中随机抽取的。
 数据配对或匹配(重复测量 (前/后))。

样本差值均值 $\bar d=\frac{\sum_{i=1}^n d_i}{n_d}$   
样本差值标准差值 $s_d=\sqrt{\frac{\sum_{i=1}^n(d_i-\bar d)^2}{n_d-1}}$

大样本检验统计量：

$$ z=\frac{\bar d-d_0}{s_d/\sqrt{n_d}}\sim N(0,1)$$
小样本检验统计量：

$$ t=\frac{\bar d-d_0}{s_d/\sqrt{n_d}}\sim t(n-1)$$

** 例子
一个减肥俱乐部声称，参加其训练班至少可以使肥胖者平均体重减轻8.5kg以上。为了验证该宣传是否可信，调查人员随机抽取了10名参加者，得到他们的体重记录如下：

| 训练前 | 94.5 |  101 |   110 | 103.5 | 97 | 88.5 | 96.5 |  101 | 104 | 116.5 |
|--------+------+------+-------+-------+----+------+------+------+-----+-------|
| 训练后 |   85 | 89.5 | 101.5 |    96 | 86 | 80.5 |   87 | 93.5 |  93 |   102 |

#+BEGIN_SRC R
before = c(94.5,101,110,103.5,97,88.5,96.5,101,104,116.5)
after = c(85,89.5,101.5,96,86,80.5,87,93.5,93,102)
t.test(before-after, mu=8.5, alternative = "greater")
#+END_SRC


** 正态总体双样本参数假设检验
*** 两样本比例检验
假定条件：
 两个总体都服从二项分布。
 可以用正态分布来近似。

 检验统计量：  
 检验 H_0 ： $p_1-p_2=0$

$$ z=\frac{\bar p_1-\bar p_2}{\sqrt{\bar p(1-\bar p)(\frac{1}{n_1}+\frac{1}{n_2})}}，其中\bar p=\frac{x_1+x_2}{n_1+n_2}=\frac{\bar p_1n_1+\bar p_2n_2}{n_1+n_2}$$

 检验 H_0 ： $p_1-p_2=d_0$

$$ z=\frac{(\bar p_1-\bar p_2)-d_0}{\sqrt{\frac{\bar p_1(1-\bar p_1)}{n_1}+\frac{\bar p_2(1-\bar p_2)}{n_2}}}$$

** 例子
民意测验专家想知道某广告是否对观众产生明显影响，为此播出前后做了两次调查：

|        | 第一次 | 第二次 |
|--------+--------+--------|
| 喜欢   |     45 |     56 |
| 不喜欢 |     35 |     47 |

#+BEGIN_SRC R
prop.test(c(45,56),c(45+35,56+47))
#+END_SRC

* 非参数假设检验  
:PROPERTIES:
:header-args: :results output :exports both
:END:

** 非参数检验
参数假设检验是在假设总体分布已知的情况下进行的. 但实践中，难以对总体的分布进行假定. 数据并不是来自所假定分布的总体, 或者，数据根本不是来自一个总体.
  
+ 单一样本的检验
  + 位置参数的检验：用 Wilcoxon 符号秩检验替代 t 检验
  + 分布一致性检验：卡方拟合优度检验和K-S单样本总体分布检验
  + 常用正态性检验：Jarque-Bera检验、Shapiro-Wilk（W检验）等
+ 双样本比较与检验
  + 卡方独立性检验和 Fisher 精确检验：两个类别变量是否相关（比较比例）
  + Wilcoxon 秩和检验法和 Mann-Whitney U 检验：替代 t 检验（比较均值）
  + 卡方两样本同质性检验和K-S两独立样本同质性检验（比较分布）
+ 多样本的比较与检验
  + 多个独立样本的 Kruskal-Wallis 秩和检验
  + 多个相关样本的 Friedman 秩和检验
  + 尺度参数的Ansari-Bradley检验和Fligner-Killeen检验

** 单一样本的检验
*** 单一样本位置参数的检验
  + 前提：总体分布未知；小样本  
  + 方法：Wilcoxon 符号秩检验
  
例子：某保险公司2016年车险索赔数额（单位：元）的随机抽样为（按升幂排列）：4632, 4728, 5052, 5064, 5484, 6972, 7696, 9048, 14760, 15013, 18730,21240, 22836, 52788, 67200. 已知2015年的索赔数额的中位数为6064元. 问2016年索赔的中位数与前一年是否有所变化?
#+BEGIN_SRC R
insure<-c(4632, 4728, 5052, 5064, 5484, 6972, 7696, 9048, 14760, 15013, 18730, 21240, 22836, 52788, 67200)
wilcox.test(insure,mu=6064)
#+END_SRC

*** 卡方拟合优度检验
卡方拟合优度检验(Chi-squared goodness of fit tests)用来检验样本是否来自于特定类型分布的一种假设检验。  
+ 前提：适用于验证离散型分布，也可验证连续型分布，但会有信息丢失    
如果掷一骰子150次并得到以下分布数据，此骰子是均匀的吗?   

| 点数     |  1 |  2 |  3 |  4 |  5 |  6 | 合计 |
|----------+----+----+----+----+----+----+------|
| 出现次数 | 22 | 21 | 22 | 27 | 22 | 36 |  150 |

$$\chi^2=\sum_{i=1}^n \frac{(f_i-e_i)^2}{e_i},\ f_i为观察到的第i类数据出现的频数，e_i为第i类数据出现的理论频数$$
#+BEGIN_SRC R
freq =c(22,21,22,27,22,36)
probs = c(1,1,1,1,1,1)/6        # 指定理论概率（均匀分布）
chisq.test(freq,p=probs)
#+END_SRC
*** K-S单样本总体分布检验（验证连续型分布）
#+BEGIN_SRC R
x=rnorm(50)
y=runif(50,0,1)
# 验证是否为均值为0，标准差为1的正态分布
ks.test(x, "pnorm", mean=0, sd=1)
# 验证是否为[0,1]的均匀分布
ks.test(y, "punif", 0,1 )
# 验证是否为参数为0.5的指数分布
ks.test(x,"pexp",0.5)
#+END_SRC
** 常用正态分布检验
+ Jarque-Bera检验(偏度和峰度的联合分布检验法)  
样本偏度和样本峰度可以联合起来作为正态性检验问题的检验统计量。  
#+BEGIN_SRC R
library(tseries)
jarque.bera.test(mtcars$mpg)
#+END_SRC
+ 一元正态性检验：夏皮洛—威尔克(Shapiro-Wilk)检验（或者W检验）  
当 8≤n≤50 时使用，小样本 n<8 检验效果不好，大样本使用K-S检验。
#+BEGIN_SRC R
shapiro.test(mtcars$mpg)
#+END_SRC

+ 其他正态分布检验（独立性）
  - AD正态性检验(ad.test) 
  - Cramer-von Mises正态性检验(cvm.test) 
  - Lilliefors 正态性检验(lillie.test) 
  - Pearson 卡方正态性检验(pearson.test)     
  - Shapiro-Francia正态性检验(sf.test) 

** 双样本比较与检验
*** 卡方独立性检验（Chi-squared tests of independence）  
在两个分类变量相互独立的原假设下，比较理论频数和实际频数的吻合程度。

$$\chi^2=\sum_{i=1}^r\sum_{k=1}^s[n_{ij}-\frac{n_{i.}n_{.j}}{n}]^2/\frac{n_{i.}n_{.j}}{n} \ \sim \ \chi^2((r-1)(s-1))$$

安全带与受伤程度的独立性检验  

| 受伤情况 |    无 | 轻微 | 较重 | 严重 |
|----------+-------+------+------+------|
| 系安全带 | 12813 |  647 |  359 |   42 |
| 没系     | 65963 | 4000 | 2642 |  303 |

#+BEGIN_SRC R
yesbelt = c(12813,647,359,42)
nobelt = c(65963,4000,2642,303)
chisq.test(rbind(yesbelt,nobelt))
#+END_SRC
** 双样本比较与检验（独立性）
+ Fisher 精确检验：当每个样本在每个类别上的结果（列联表单元格中的观察数）小于5个时采用
#+BEGIN_SRC R
compare<-matrix(c(60,32,3,11),nr = 2, dimnames = list(c("cancer", "normal"), c("smoke", "Not smoke")))
fisher.test(compare, alternative = "greater")
#+END_SRC

** 双样本比较与检验（比较中心位置）
+ Wilcoxon 秩和检验法  
在不知总体分布时, 使用 t 检验可能有风险. 考虑采用Wilcoxon秩和检验法.    
Mann-Whitney U 检验与Wilcoxon检验统计量几乎相同。

有糖尿病的和正常的老鼠重量为(单位:克)  
糖尿病鼠:42, 44, 38, 52, 48, 46, 34, 44, 38;  
正常老鼠:34, 43, 35, 33, 34, 26, 30, 31, 31, 27, 28, 27, 30, 37, 32.  
#+BEGIN_SRC R
diabetes<-c(42,44,38,52,48,46,34,44,38)
normal<-c(34,43,35,33,34,26,30,31,31,27,28,27,30,37,32)
wilcox.test(diabetes,normal)
#+END_SRC
** 双样本比较与检验（同分布检验）
+ 卡方两样本同质性检验(Chi-squared tests for homogeneity)  
用来检验各行是否来自同一个总体。如果各行因子来自于相同的总体，每一类的出现概率应该是差不多的。过程与 *卡方独立性检验* 一样，原假设为两样本来自同一个总体。  

+ K-S两独立样本同质性检验  
假定有分别来自两个独立总体的样本，想要检验其总体分布相同的原假设。
#+BEGIN_SRC R
x1=c(48,47,44,45,46,47,43,47,42,48)  
x2=c(36,45,47,38,39,42,36,42,46,35)  
ks.test(x1,x2) 
#+END_SRC
** 多样本的比较与检验（比较位置参数）
+ 多个独立样本的Kruskal-Wallis 秩和检验  
  在数据非正态的情况下代替单因素方差分析，原假设为各总体中心位置都相等

学校要对300份奖学金申请进行评价，安排了3个评价人。为检查评价人标准是否一致，随机选择比较3个评价人的评分。评分等级不服从正态假定，采用非参数检验。  

评价者1：4，3，4，5，2，3，4，5，4，4，5，4   
评价者2：4，4，5，5，4，5，4，4，5，5，4，5   
评价者3：3，4，2，4，4，5，3，4，2，2，1，1  
#+BEGIN_SRC R
scores = c(4,3,4,5,2,3,4,5,4,4,5,5,4,5,4,4,3,4,2,4,5,5,4,4)
person = c(1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3)
kruskal.test(scores ~ person)
#+END_SRC
** 多样本的比较与检验（比较位置参数）
+ 多个相关样本的 Friedman 秩和检验  
  在数据严重偏态且样本量较小的情况下代替重复测量的方差分析
  
检验相同被试对3个影响因素的评分  
分数表示：-2=非常负面，-1=负面，0=中性，1=积极，2=非常积极]

| 影响因素 |  1 | 2 |  3 | 4 |  5 |  6 |  7 |  8 |  9 | 10 | 11 | 12 |
|----------+----+---+----+---+----+----+----+----+----+----+----+----|
| 电影     | -1 | 1 |  0 | 2 |  0 | -2 | -1 |  0 | -1 |  1 |  1 | -1 |
| 电视     |  0 | 0 |  1 | 0 | -1 | -2 | -1 |  1 | -1 |  0 |  1 | -1 |
| 摇滚     | -1 | 0 | -2 | 1 | -1 | -2 |  0 | -1 | -1 |  1 | -1 | -2 |
#+BEGIN_SRC R
evaluation = matrix(c(-1,0,-1,1,0,0,0,1,-2,2,0,1,0,-1,-1,-2,-2,-2,-1,-1,0,0,1,-1,-1,-1,-1,1,0,1,1,1,1,-1,-1,-2),nrow=12,byrow=TRUE)
friedman.test(evaluation)
#+END_SRC


** 多样本的比较与检验（比较尺度参数）
+ 尺度参数的Ansari-Bradley检验和Fligner-Killeen检验  
  多个样本总体均值相等条件下，检验总体方差是否相等

三名运动员比赛打靶，各打10发子弹，打中的环数 A：[8, 7, 9, 10, 9, 6, 5, 8, 10, 5]；B：[8, 7, 9, 6, 8, 9, 10, 7, 8, 9]；C：[10, 10, 9, 6, 8, 3, 5, 6, 7, 4]. 问这三名运动员的稳定性是否一样？
#+BEGIN_SRC R
x<-list(A=c(8,7,9,10,9,6,5,8,10,5), B=c(8,7,9,6,8,9,10,7,8,9), C=c(10,10,9,6,8,3,5,6,7,4))
fligner.test(x)

ansari.test(x$A,x$B)
#+END_SRC

** 补充作业需要的代码
#+BEGIN_SRC R
#连续变量转化为类别变量
x <- c(1,0,1,1,0,0,1)
xfac <- factor(x)

#连续变量转化为有序变量
y <- c(rep(1,5),rep(2,4),rep(3,6))
yord <- ordered(y)

#箱线图
boxplot(mtcars$wt)
#分类箱线图
boxplot(mtcars$wt~mtcars$am)

#+END_SRC

* 信度检验
:PROPERTIES:
:header-args: :results output :exports both :session reliability
:END:
** 信度

* 因子分析
:PROPERTIES:
:header-args: :results output :exports both :session factor
:END:
** 主成分分析和因子分析的区别
+ 主成分分析（Principle Component Analysis）是数据降维技术，它能将大量相关变量转化为较少的不相关的变量，并且尽可能保留原始数据的信息，这些不相关的变量就是主成分。  
  - 例如，定制衣服时，需要测量人体的许多尺寸，如上体长、手臂长、胸围、颈围、总肩宽等. 可以选出它们的某个线性组合，使之基本能够刻画人对服装的要求这个线性组合就是诸多尺寸的主成分.


+ 因子分析（Factor Analysis）是通过寻找数据中隐藏的结构来解释观测变量间的关系，隐藏的结构就用潜在的因子来表示，因子之间是可以相关的。
  - 为了测验中学生的知识与能力，出40道题目让学生回答，每道题目单独计分，希望找出有限个不可观测的潜在变量来解释这40个随机变量。这种不可观测的潜在变量一般不能表示为原来随机变量的线性组合，但却是有实际意义的，例如语言表达能力、推理能力、艺术修养能力、历史知识和生活常识等。

** 主要步骤：  
  + 数据预处理：一般程序会自动标准化  
  + 选择模型：主成分分析还是因子分析  
  + 判断要选择的主成分/因子的个数  
  + 选择主成分/因子  
  + 旋转主成分/因子  
  + 解释结果  
  + 计算主成分或因子得分  

** 主成分分析
+ 假设数据集有p个指标，可看作p个随机变量 $X_1， X_2， \cdots，X_p$，主成分分析就把这个p指标转变为p个指标的线性组合，而这些新的指标 $F_1， F_2， \cdots， F_k(k\le p)$ 要充分反映原指标的信息，并且相互独立。  

$$F_1=u_{11}X_1+u_{21}X_2+\cdots+u_{p1}X_p \\ F_2=u_{12}X_1+u_{22}X_2+\cdots+u_{p2}X_p \\ \cdots \\ F_p=u_{1p}X_1+u_{2p}X_2+\cdots+u_{pp}X_p$$

+ 要求满足：  
  - 每个主成分的系数平方和为1。即
    $$u_{1i}^2+u_{2i}^2+\cdots+u_{pi}^2=1$$
  - 主成分之间相互独立，即无重叠的信息。即
    $$ Cov(F_i，F_j）=0，i\neq j,i,j=1,2，\cdots，p $$
  - 主成分的方差依次递减，重要性依次递减，即
    $$ Var(F_1)\ge Var(F_2)\ge \cdots \ge Var(F_p) $$

1. 判断主成分的个数
  - 基于特征值：特征值代表主成分所解释的方差，保留特征值大于1的主成分  
  - 基于碎石图：保留碎石图上变化最大处之上的主成分  
  - 平行分析：如果真实数据的特征值大于随机数据矩阵的平均特征值，则保留

#+BEGIN_SRC R :results output graphics :file 4.png :width 800 :height 600
library(psych)

fa.parallel(USJudgeRatings[,-1], fa="pc")
#+END_SRC

#+RESULTS:
[[file:4.png]]

1 提取主成分   

  + principal(r, nfactors=, rotate=, scores=)  
    - 其中：r是相关系数矩阵或原始数据矩阵；nfactors设定主成分的个数；rotate指定旋转的方法（默认为最大方差旋转varimax）；scores设定是否需要计算主成分得分（默认不需要）


#+BEGIN_SRC R
pc <- principal(USJudgeRatings[,-1], nfactors=1)
pc
#+END_SRC

#+RESULTS:
#+begin_example

Principal Components Analysis
Call: principal(r = USJudgeRatings[, -1], nfactors = 1)
Standardized loadings (pattern matrix) based upon correlation matrix
      PC1   h2     u2 com
INTG 0.92 0.84 0.1565   1
DMNR 0.91 0.83 0.1663   1
DILG 0.97 0.94 0.0613   1
CFMG 0.96 0.93 0.0720   1
DECI 0.96 0.92 0.0763   1
PREP 0.98 0.97 0.0299   1
FAMI 0.98 0.95 0.0469   1
ORAL 1.00 0.99 0.0091   1
WRIT 0.99 0.98 0.0196   1
PHYS 0.89 0.80 0.2013   1
RTEN 0.99 0.97 0.0275   1

                 PC1
SS loadings    10.13
Proportion Var  0.92

Mean item complexity =  1
Test of the hypothesis that 1 component is sufficient.

The root mean square of the residuals (RMSR) is  0.04 
 with the empirical chi square  6.21  with prob <  1 

Fit based upon off diagonal values =
#+end_example

- PC1 列为成分载荷，即观测变量与第一主成分的相关系数。成分载荷可以用来解释主成分的含义。

$$\rho(x_i,F_j)=\frac{u_{ij}\lambda_j}{\sigma_i\sqrt{\lambda_j}}=\frac{u_{ij}\sqrt{\lambda_j}}{\sigma_i}$$

- h2列为成分公因子方差（communality），即原始变量信息的被提取率，所有主成分对每个变量的方差解释度，数值为观测变量与所有主成分的相关系数的平方和；而 u2 列为成分唯一性（uniqueniesses），即变量方差中无法被主成分解释的比例，数值为1-h2.

- SS loadings 为与某个主成分相关联的特征值 $\lambda_j$ ；Proportion Var 为某个主成分对整个数据集的解释程度或贡献率，数值上为其相关联的特征值在特征值总和中所占的比例；Cumulative Var 为到某个主成分为止的主成分累计的解释度或累计贡献率，数值上为特征值占特征值总和累计比例。

$$\lambda_i/\sum_{i=1}^p\lambda_i,\qquad \sum_{i=1}^k\lambda_i/\sum_{i=1}^p\lambda_i$$

1.主成分旋转  
  + 旋转的目的是将载荷矩阵变得更容易解释，尽可能去除掉主成分中的噪声。  
  + 两种旋转方式：  
    - 正交旋转：保持主成分不相关，最常用的正交旋转是方差极大旋转，它尽量使得载荷矩阵的列只有少数几个很大的载荷。  
    - 斜交旋转：允许主成分相关


#+BEGIN_SRC R
principal(Harman23.cor$cov, nfactors=2, rotate="none") 
# 方差极大旋转
principal(Harman23.cor$cov, nfactors=2, rotate="varimax")

#+END_SRC

#+RESULTS:
#+begin_example
Principal Components Analysis
Call: principal(r = Harman23.cor$cov, nfactors = 2, rotate = "none")
Standardized loadings (pattern matrix) based upon correlation matrix
                PC1   PC2   h2    u2 com
height         0.86 -0.37 0.88 0.123 1.4
arm.span       0.84 -0.44 0.90 0.097 1.5
forearm        0.81 -0.46 0.87 0.128 1.6
lower.leg      0.84 -0.40 0.86 0.139 1.4
weight         0.76  0.52 0.85 0.150 1.8
bitro.diameter 0.67  0.53 0.74 0.261 1.9
chest.girth    0.62  0.58 0.72 0.283 2.0
chest.width    0.67  0.42 0.62 0.375 1.7

                       PC1  PC2
SS loadings           4.67 1.77
Proportion Var        0.58 0.22
Cumulative Var        0.58 0.81
Proportion Explained  0.73 0.27
Cumulative Proportion 0.73 1.00

Mean item complexity =  1.7
Test of the hypothesis that 2 components are sufficient.

The root mean square of the residuals (RMSR) is  0.05 

Fit based upon off diagonal values =

Principal Components Analysis
Call: principal(r = Harman23.cor$cov, nfactors = 2, rotate = "varimax")
Standardized loadings (pattern matrix) based upon correlation matrix
                RC1  RC2   h2    u2 com
height         0.90 0.25 0.88 0.123 1.2
arm.span       0.93 0.19 0.90 0.097 1.1
forearm        0.92 0.16 0.87 0.128 1.1
lower.leg      0.90 0.22 0.86 0.139 1.1
weight         0.26 0.88 0.85 0.150 1.2
bitro.diameter 0.19 0.84 0.74 0.261 1.1
chest.girth    0.11 0.84 0.72 0.283 1.0
chest.width    0.26 0.75 0.62 0.375 1.2

                       RC1  RC2
SS loadings           3.52 2.92
Proportion Var        0.44 0.37
Cumulative Var        0.44 0.81
Proportion Explained  0.55 0.45
Cumulative Proportion 0.55 1.00

Mean item complexity =  1.1
Test of the hypothesis that 2 components are sufficient.

The root mean square of the residuals (RMSR) is  0.05 

Fit based upon off diagonal values =
#+end_example

1.获得主成分得分系数和得分  
   + 主成分得分的系数原始变量线性组合的系数 $u_{ij}$  
   + 主成分得分即由原始变量降维后形成的新主成分的变量值（已标准化）。

#+BEGIN_SRC R
pc <- principal(USJudgeRatings[,-1], nfactors=1, score=TRUE) 
# 主成分得分系数
pc$weights
# 主成分得分
head(pc$scores)

#+END_SRC

#+RESULTS:
#+begin_example

            PC1
INTG 0.09063298
DMNR 0.09010751
DILG 0.09561212
CFMG 0.09506461
DECI 0.09484596
PREP 0.09719916
FAMI 0.09633895
ORAL 0.09823407
WRIT 0.09771359
PHYS 0.08819290
RTEN 0.09731516

                      PC1
AARONSON,L.H.  -0.1857981
ALEXANDER,J.M.  0.7469865
ARMENTANO,A.J.  0.0704772
BERDON,R.I.     1.1358765
BRACKEN,J.J.   -2.1586211
BURNS,E.B.      0.7669406
#+end_example


+ 由主成分分析可以生成一个新变量来替代11个原始变量，公式为：  

$$PC1=0.091\times INTG+0.090\times DMNR+0.096\times DILG+\cdots +0.097\times RTEN$$

** 因子分析
+ 设 $X_i(i=1,2,\cdots,p)$ p个变量，如果表示为：

$$X_i=\mu_i+a_{i1}F_1+\cdots+a_{im}F_m+\varepsilon_i(m\le p)$$ 

  - $F_1,F_2,\cdots,F_m$ 称为公共因子，是不可观测的变量，它们的系数称为因子载荷。 $\varepsilon_i$ 是特殊因子，是不可能被前m个公共因子包含的部分。  

并且满足：
- $cov(F,\varepsilon)=0$ ，即 $F,\varepsilon$ 不相关  
- $F_1,F_2,\cdots,F_m$ 互不相关，方差为1  
- $\varepsilon_i\sim N(0,\sigma_i^2)$ 互不相关，方差不一定相等  

- 例子：对6个心理学测验进行分析。112个人参与了6个测验，包括普通智力测验（general）、画图测验（picture）、积木测验（blocks）、迷宫测验（maze）、阅读测验（reading）和词汇测验（vocab）。如何用一组较少的、潜在的心理学因素来解释参与者的测验得分？

- 判断提取公共因子的个数：取高不取低
#+BEGIN_SRC R :results output graphics :file 5.png :width 800 :height 600
covariances <- ability.cov$cov
correlations <- cov2cor(covariances)
fa.parallel(correlations, n.obs=112, fa="fa")

#+END_SRC

#+RESULTS:
[[file:5.png]]

2. 提取公共因子  
   + fa(r, nfactors=, n.obs=, rotate=, scores=, fm=)]
     - 其中：r 是相关系数矩阵或原始数据矩阵；nfactors设定提取因子个数；n.obs是观测数（r是相关系数矩阵时需要提供）；rotate指定旋转的方法（默认为互变异数最小法"oblimin"）；scores设定是否计算因子得分（默认不计算）；fm设定因子化方法（默认极小残差法"minres"，常用最大似然法"ml"，主轴迭代法"pa"）
#+BEGIN_SRC R
# 未旋转的主轴迭代因子法
fa <- fa(correlations, nfactors=2, rotate="none", fm="pa")
fa
#+END_SRC

#+RESULTS:
#+begin_example

Factor Analysis using method =  pa
Call: fa(r = correlations, nfactors = 2, rotate = "none", fm = "pa")
Standardized loadings (pattern matrix) based upon correlation matrix
         PA1   PA2   h2    u2 com
general 0.75  0.07 0.57 0.432 1.0
picture 0.52  0.32 0.38 0.623 1.7
blocks  0.75  0.52 0.83 0.166 1.8
maze    0.39  0.22 0.20 0.798 1.6
reading 0.81 -0.51 0.91 0.089 1.7
vocab   0.73 -0.39 0.69 0.313 1.5

                       PA1  PA2
SS loadings           2.75 0.83
Proportion Var        0.46 0.14
Cumulative Var        0.46 0.60
Proportion Explained  0.77 0.23
Cumulative Proportion 0.77 1.00

Mean item complexity =  1.5
Test of the hypothesis that 2 factors are sufficient.

The degrees of freedom for the null model are  15  and the objective function was  2.48
The degrees of freedom for the model are 4  and the objective function was  0.07 

The root mean square of the residuals (RMSR) is  0.03 
The df corrected root mean square of the residuals is  0.06 

Fit based upon off diagonal values = 0.99
Measures of factor score adequacy             
                                                   PA1  PA2
Correlation of (regression) scores with factors   0.96 0.92
Multiple R square of scores with factors          0.93 0.84
Minimum correlation of possible factor scores     0.86 0.68
#+end_example

???
最大似然法是最常用的方法，但是有时最大似然法不收敛，本例为说明旋转过程，采用主轴迭代法。

   + 解释因子载荷矩阵（结果中的第一个矩阵）的统计特征  
  
   + PA1、PA2列为因子载荷，是第i个变量与第j个公共因子的相关系数 $a_{ij}$ 。  
  
   + h2列为变量 $X_i$的共同度，是因子载荷矩阵的第i行因子载荷的平方和。记为 $h_i^2=\sum_{i=1}^ma_{ij}^2 $，所有的公共因子和特殊因子对变量 $X_i$ 的贡献为1。如果共同度非常靠近1，则说明因子分析的效果好，从原变量空间到公共因子空间的转化性质好。  
  
  + SS loadings为因子载荷矩阵中各列元素的平方和 $S_j=\sum_{i=1}^pa_{ij}^2$ ，因子 $F_j$ 对所有的 $X_i$ 的方差贡献和。衡量 $F_j$ 的相对重要性。
  
  + 两个因子解释了6个测验60%的方差，但是因子载荷不好解释，需要进行因子旋转

3. 因子旋转：正交旋转"varimax"  
   + 旋转后，阅读和词汇在第一个因子上的载荷比较大，而画图和积木在第二个因子上的载荷比较大，说明存在一个语言智力因子和图像智力因子

#+BEGIN_SRC R
# 正交旋转
fa.varimax <- fa(correlations, nfactors=2, rotate="varimax", fm="pa")
fa.varimax
#+END_SRC

#+RESULTS:
#+begin_example

Factor Analysis using method =  pa
Call: fa(r = correlations, nfactors = 2, rotate = "varimax", fm = "pa")
Standardized loadings (pattern matrix) based upon correlation matrix
         PA1  PA2   h2    u2 com
general 0.49 0.57 0.57 0.432 2.0
picture 0.16 0.59 0.38 0.623 1.1
blocks  0.18 0.89 0.83 0.166 1.1
maze    0.13 0.43 0.20 0.798 1.2
reading 0.93 0.20 0.91 0.089 1.1
vocab   0.80 0.23 0.69 0.313 1.2

                       PA1  PA2
SS loadings           1.83 1.75
Proportion Var        0.30 0.29
Cumulative Var        0.30 0.60
Proportion Explained  0.51 0.49
Cumulative Proportion 0.51 1.00

Mean item complexity =  1.3
Test of the hypothesis that 2 factors are sufficient.

The degrees of freedom for the null model are  15  and the objective function was  2.48
The degrees of freedom for the model are 4  and the objective function was  0.07 

The root mean square of the residuals (RMSR) is  0.03 
The df corrected root mean square of the residuals is  0.06 

Fit based upon off diagonal values = 0.99
Measures of factor score adequacy             
                                                   PA1  PA2
Correlation of (regression) scores with factors   0.96 0.92
Multiple R square of scores with factors          0.91 0.85
Minimum correlation of possible factor scores     0.82 0.71
#+end_example

   + 正交旋转后，每个变量的共同度（h2）不变，两个因子的载荷分配发生了变化（SS loadings和Proportion Var），但是它们的总方差贡献（Cumulative Var）仍为60%

4. 因子旋转：斜交旋转"promax"  
#+BEGIN_SRC R
fa.promax <- fa(correlations, nfactors=2, rotate="promax", fm="pa")
fa.promax
#+END_SRC

#+RESULTS:
#+begin_example
Loading required namespace: GPArotation

Factor Analysis using method =  pa
Call: fa(r = correlations, nfactors = 2, rotate = "promax", fm = "pa")
Standardized loadings (pattern matrix) based upon correlation matrix
          PA1   PA2   h2    u2 com
general  0.37  0.48 0.57 0.432 1.9
picture -0.03  0.63 0.38 0.623 1.0
blocks  -0.10  0.97 0.83 0.166 1.0
maze     0.00  0.45 0.20 0.798 1.0
reading  1.00 -0.09 0.91 0.089 1.0
vocab    0.84 -0.01 0.69 0.313 1.0

                       PA1  PA2
SS loadings           1.83 1.75
Proportion Var        0.30 0.29
Cumulative Var        0.30 0.60
Proportion Explained  0.51 0.49
Cumulative Proportion 0.51 1.00

 With factor correlations of 
     PA1  PA2
PA1 1.00 0.55
PA2 0.55 1.00

Mean item complexity =  1.2
Test of the hypothesis that 2 factors are sufficient.

The degrees of freedom for the null model are  15  and the objective function was  2.48
The degrees of freedom for the model are 4  and the objective function was  0.07 

The root mean square of the residuals (RMSR) is  0.03 
The df corrected root mean square of the residuals is  0.06 

Fit based upon off diagonal values = 0.99
Measures of factor score adequacy             
                                                   PA1  PA2
Correlation of (regression) scores with factors   0.97 0.94
Multiple R square of scores with factors          0.93 0.88
Minimum correlation of possible factor scores     0.86 0.77
#+end_example

   + 斜交旋转后，因子载荷矩阵中的载荷不再是变量和因子的相关系数，而是因子对变量进行回归后的标准化回归系数，所以载荷有可能会大于1或小于-1  
   + 与正交旋转相同，每个变量的共同度（h2）不变，两个因子的载荷分配发生变化，但累计方差贡献率（Cumulative Var）不变，仍为60%  
   + 此时，两个因子不再正交独立，相关系数为0.55（因子相关矩阵）

   + 两因子载荷图：展示各原始变量在各因子上的载荷
#+BEGIN_SRC R  :results output graphics :file 6.png :width 600 :height 800
factor.plot(fa.promax, labels=rownames(fa.promax$loadings))
#+END_SRC

#+RESULTS:
[[file:6.png]]

   + 因子载荷结构图：展示潜在因子与变量之间的结构

#+BEGIN_SRC R :results output graphics :file 7.png :width 600 :height 800
fa.diagram(fa.promax, simple=FALSE)
#+END_SRC

#+RESULTS:
[[file:7.png]]

5. 因子得分系数  

$$PA1=0.078\times general+0.020\times picture+0.037\times blocks+\cdots +0.177\times vocab$$

$$PA2=0.211\times general+0.090\times picture+0.702\times blocks+\cdots +0.036\times vocab$$

#+BEGIN_SRC R
# 因子得分
fa.promax$scores
# 因子得分系数
fa.promax$weights

#+END_SRC

#+RESULTS:
#+begin_example

NULL

               PA1        PA2
general 0.07836571 0.21091463
picture 0.02000694 0.09038071
blocks  0.03662858 0.70209400
maze    0.02700266 0.03453381
reading 0.74276722 0.03012597
vocab   0.17683183 0.03583324
#+end_example

** 因子分析的前提条件
+ 样本量没有通用的要求，一般50以下太少，100较少，200基本足够，300较好，500非常好，超过1000特别合适。  
+ KMO样本测度检验数据中是否存在显著的因子。KMO在0.9以上，非常适合；0.8-0.9很适合；0.7-0.8适合；0.6-0.7不太适合；0.5-0.6很勉强；0.5以下，不适合；因子分析前应该剔除掉KMO小于0.5的原始变量。   
+ 巴特莱特球体检验：原假设H0为相关系数矩阵R为单位阵I，即原始变量两两独立。如果拒绝原假设才可作因子分析

#+BEGIN_SRC R
# KMO 样本测度
KMO(USJudgeRatings[,-1])
# 巴特莱特球体检验
cortest.bartlett(correlations,n=112)

#+END_SRC

#+RESULTS:
#+begin_example

Kaiser-Meyer-Olkin factor adequacy
Call: KMO(r = USJudgeRatings[, -1])
Overall MSA =  0.91
MSA for each item = 
INTG DMNR DILG CFMG DECI PREP FAMI ORAL WRIT PHYS RTEN 
0.88 0.92 0.92 0.91 0.91 0.90 0.88 0.93 0.91 0.90 0.90

$chisq
[1] 268.3538

$p.value
[1] 2.027158e-48

$df
[1] 15
#+end_example
