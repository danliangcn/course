#+TITLE: 线性回归
#+AUTHOR: 厦门大学公共事务学院
#+EMAIL: 
#+OPTIONS: H:2 toc:nil num:t tex:t ^:nil
#+LATEX_CLASS: beamer
#+COLUMNS: %45ITEM %10BEAMER_env(Env) %10BEAMER_act(Act) %4BEAMER_col(Col) %8BEAMER_opt(Opt)
#+BEAMER_THEME: default
#+BEAMER_COLOR_THEME:
#+BEAMER_FONT_THEME:
#+BEAMER_INNER_THEME:
#+BEAMER_OUTER_THEME:
#+BEAMER_HEADER:
#+LATEX_HEADER: \usepackage{ctex}
#+LATEX_COMPILER: xelatex


* 线性回归基础  
:PROPERTIES:
:header-args: :results output :exports both :session lregress
:END:

** R语言的list对象
list对象可以用来“包裹”完全不同类型的变量对象，甚至可以是list对象，可以方便地将不同类型的参数传递给函数，或者获取一些不同类型对象组成的结果。
#+BEGIN_SRC R
mylist <- list(a=1, b=c(1,2), c="hello")
mylist$a
mylist$b
mylist$c
mylist[3]
mylist[["c"]]
#+END_SRC

** lm()函数的用法
先来一个假想的例子
#+BEGIN_SRC R
x <- 1:100
y <- 3*x + rnorm(100)
res <- lm(y~x)
# 回归结果汇总
summary(res)
#+END_SRC
提取回归相关结果
#+BEGIN_SRC R :exports code
# 提取回归系数
coef(res)

# 回归方程的残差
res$residuals
resid(res)

# 提取协方差矩阵
vcov(res)

# 计算标准误
sqrt(diag(vcov(res)))

# 提取拟合值
predict(res)

# 获取自变量新数据的预测值，预测区间，置信区间
xnew <- data.frame(x=seq(-1,1,1))
predict(res, newdata=xnew, interval = "prediction")
predict(res, newdata=xnew, interval = "confidence")
#+END_SRC

** 回归示例：母亲教育与子女认知能力
数据集：[[./kidiq.dta][母亲教育与子女认知能力]]
| 变量      | 描述                    |
|-----------+-------------------------|
| kidscore   | 3-4岁小孩的认知测试分数 |
| mom_hs   | 母亲是否上过高中        |
| mom_iq   | 母亲的智商              |

** 回归示例：单个预测变量

+ 采用母亲的智商预测3到4岁小孩的认知测试分数
#+BEGIN_SRC R
library("foreign")
# 清除内存
rm(list=ls())

# 载入数据
kidiq <- read.dta("kidiq.dta")

attach(kidiq)

fit0 <- lm(kid_score~mom_iq)

summary(fit0)
#+END_SRC

** 回归示例：多个预测变量
+ 自变量：母亲是否上过高中、母亲的智商
+ 解释系数和截距
#+BEGIN_SRC R
fit1 <- lm (kid_score ~ mom_hs + mom_iq)

summary(fit1)
#+END_SRC

+ 系数的解释：保持其他变量不变，预测变量单位变动相应的响应变量变动大小。

+ 注意：有时候在保持其他变量不变的情况下是不可能变动某个变量的，例如回归中同时包括IQ和 \(IQ^{2}\)，或者有交互项 mom_hs*mom_i
q.
** 回归示例：去除截距和添加交互项
+ 没有截距（常数项）
#+BEGIN_SRC R
fit2 <- lm (kid_score ~ mom_hs + mom_iq - 1)

summary(fit2)
#+END_SRC

+ 添加交互项
增加一个交互项以允许IQ的回归系数随高中完成情况不同而变动
#+BEGIN_SRC R
fit3 <- lm (kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq)

summary(fit3)
#+END_SRC
+ 解释系数和截距  
  - 截距： $IQ=0 \quad hs=0$（无意义）  
  - mom_hs的系数： IQ=0时，是否完成高中相应的孩子得分差异  
  - mom_iq的系数： 未完成高中母亲中，IQ增加所相应的孩子得分差异，红线斜率  
  - 交互项的系数：母亲是否完成高中两组之间在IQ斜率上的差别  
+ 快速添加交互项
#+BEGIN_SRC R
fit4 <- lm (kid_score ~ mom_hs * mom_iq)

summary(fit4)
#+END_SRC
** 回归绘图：par()设置
+ 设置文本大小：
- cex 文本大小（2代表2倍大小） 
- cex.axis 坐标轴刻度值大小 
- cex.lab 坐标轴标识大小
- cex.main 图标题大小
- cex.sub 图副标题大小
- font 字体
- font.axis 坐标轴字体
- srt 图中文本旋转
- las 边缘文本旋转
- text()函数用来在plot制图中添加文字
- bg 背景色
- col 线条、符号颜色
- col.axis 坐标轴刻度值颜色
- colors()可了解颜色选择
- lty 线条类型
- lwd 线条宽度
- pch 数据符号
- lab 刻度数量
- xaxp x轴的刻度数量
- tck，tcl 刻度相对于图的长度
- mgp 坐标轴元素的间隔 eg. c(3,1,0)代表坐标轴的标识、刻度值、坐标轴线的位置
- usr 坐标轴范围（xmin,xmax,ymin,ymax）
- xlog,ylog x,y轴采用对数尺度
#+BEGIN_SRC R :results output graphics :file 1.png :width 800 :height 600
# 数据的散点图
plot(x=mom_iq, y=kid_score)
# 添加回归线
abline(fit0$coefficients[1], fit0$coefficients[2], col="black")
#+END_SRC

** 绘制更美观的散点图
#+BEGIN_SRC R :results output graphics :file 2.png :width 800 :height 600
# 生成自变量新数据
iqhyp <- seq(70,140,1)
xnew <- data.frame(mom_iq=iqhyp)
# 提取预测值和置信区间
kidpred <- predict(fit0, newdata=xnew, interval="confidence", level=0.95)
# 确定制图参数和绘图区范围，暂不绘制点与坐标
par(cex.lab=1.5,mgp=c(2.5,0.8,0),family="STKaiti")
plot(x=mom_iq, y=kid_score, xaxt="n", yaxt="n", type="n", xlab="母亲智商", ylab="小孩认知测试分数")
# 绘制预测值置信区间
xpoly <- c(iqhyp, rev(iqhyp), iqhyp[1])
ypoly <- c(kidpred[,2], rev(kidpred[,3]), kidpred[1,2])
polygon(x=xpoly, y=ypoly, col="grey60", border=FALSE)
# 绘制回归线
lines(x=iqhyp, y=kidpred[,1], col="black")
# 按照母亲的教育程度标识数据点
points(x=mom_iq[mom_hs==0], y=kid_score[mom_hs==0],col="red",pch=20)
points(x=mom_iq[mom_hs==1], y=kid_score[mom_hs==1],col="blue",pch=20)
# 绘制简化的坐标
axis (1, c(80,100,120,140))
axis (2, c(20,60,100,140))
# 绘制图例
legend(118,38,legend = c("高中以下","高中以上"), col = c("red","blue"), pch=20, bty="n",cex=1.5)
#+END_SRC

#+BEGIN_SRC R
detach(kidiq)
#+END_SRC
* 线性回归假定和统计推断
:PROPERTIES:
:header-args: :results output :exports both 
:END:
** 线性回归模型的表达式
线性回归的两种表达式：

$$\begin{aligned}
  y_i & =  X_i \beta+\epsilon_i \\
      & =  \beta_1 X_{i1}+\cdots + \beta_k X_{ik} + \epsilon_i 
\end{aligned},\qquad for \quad i=1,\cdots , n$$

其中， $\epsilon_i$ 相互独立，服从均值为0，标准差为 $\sigma$ 正态分布  
或者

$$y_i \sim N(X_i \beta, \sigma^2),\qquad for \quad i=1,\cdots , n$$

其中， $X$ 是 $n\times k$ 的预测变量矩阵，第 $i$ 行为 \(X_{i}\)， $\beta$ 是长度为 $k$ 的列向量   

** 线性回归的矩阵形式
方程表达：
\[y_i=\beta_0+\beta_1 x_{1i}+\beta_2 x_{2i}+\epsilon_i\]
矩阵表达：
\[\begin{aligned}
&\mathbf{y}=&\ &\mathbf{X}\ & \ &\boldsymbol{\beta} &+ \ &\boldsymbol{\epsilon} \\
n&\times 1  &n &\times k    &k  &\times 1           &n   &\times 1
\end{aligned}\]
矩阵展开：
\begin{equation*}
\begin{bmatrix}
y_1 \\
y_2 \\
\vdots \\
y_n
\end{bmatrix}
=
\begin{bmatrix}
    1      & x_{11} & x_{12} & \ldots & x_{1k} \\
    1      &x_{12}  & x_{22} & \ldots & x_{2k} \\
    \vdots & \vdots & \vdots & \ddots & \vdots \\
    1      &x_{1n}  & x_{2n} & \ldots & x_{nk}
  \end{bmatrix}
\begin{bmatrix}
\beta_0 \\
\beta_1 \\
\vdots \\
\beta_k
\end{bmatrix}
+
\begin{bmatrix}
\epsilon_1 \\
\epsilon_2 \\
\vdots \\
\epsilon_n
\end{bmatrix}
\end{equation*}

干扰项的均值
\begin{equation*}
E(\epsilon)=
\begin{bmatrix}
E(\epsilon_1 )\\ E(\epsilon_2 )\\ \vdots \\ E(\epsilon_n)
\end{bmatrix}
=
\begin{bmatrix}
0\\ 0\\ \vdots \\ 0
\end{bmatrix}
\end{equation*}

干扰项的协方差矩阵
\begin{equation*}
\Sigma = 
\begin{bmatrix}
var(\epsilon_1 ) &cov(\epsilon_1 , \epsilon_2 ) &\dots &cov(\epsilon_1 ,\epsilon_n ) \\
cov(\epsilon_2 ,\epsilon_1 ) &var(\epsilon_2 ) &\dots &cov(\epsilon_2 ,\epsilon_n ) \\
\vdots & \vdots & \ddots & \vdots \\
cov(\epsilon_n ,\epsilon_1 ) &cov(\epsilon_n , \epsilon_2 ) &\dots &var(\epsilon_n ) \\
\end{bmatrix}
=
\begin{bmatrix}
E(\epsilon_{1}^2 ) &E(\epsilon_1 \epsilon_2 ) &\dots &E(\epsilon_1 \epsilon_n ) \\
E(\epsilon_2 \epsilon_1 ) &E(\epsilon_{2}^2 ) &\dots &E(\epsilon_2 \epsilon_n ) \\
\vdots & \vdots & \ddots & \vdots \\
E(\epsilon_n \epsilon_1 ) &E(\epsilon_n \epsilon_2 ) &\dots &E(\epsilon_{n}^2 ) \\
\end{bmatrix}
\end{equation*}

可以简化成外积形式
\[\Sigma=E(\boldsymbol{\epsilon} \boldsymbol{\epsilon^{'}})\]

如果线性回归假定成立（随机抽样假定和同方差假定），那么协方差矩阵有更简单的形式。
\begin{equation*}
\Sigma = 
\begin{bmatrix}
\epsilon^2 &0 &\dots &0 \\
0          &\epsilon^2 &\dots &0 \\
\vdots & \vdots & \ddots & \vdots \\
0 &0 &\dots &\epsilon^2 
\end{bmatrix}
=\sigma^2 \boldsymbol{I}
\end{equation*}

** 最小二乘法拟合模型 

+ 采用最小二乘法拟合模型后得到估计量 $\hat \beta$ 和 $\hat \sigma$

  - 找到让误差平方和最小的 \(\boldsymbol{\hat \beta}\)： $\sum_{i=1}^{n}(y_i-X_i \hat \beta)^2$ 
  
  - 对于给定的 $X,y$ , 当 $\hat\beta=(X^{'}X)^{-1}X^{'}y$ 时，误差平方和最小
  
  - 同时，估计协方差矩阵 $V_{\beta}\hat \sigma^2$ ，其中 $V_{\beta}=(X^tX)^{-1}$ 相应的对角线元素就是回归系数 $\beta$ 的方差，即 $\sqrt{V_{\beta 11}}\hat \sigma$

+ 估计量的标准：
  - 无偏性：\(E(\hat\beta-\beta) \) 
  - 有效性：平均而言与真实值最近。\(MSE=E[(\beta-\hat\beta)^2]=Var(\hat\beta)+Bias(\hat\beta|\beta)^2\)
  - 一致性：随着样本量增加，渐进于真实值（计量经济领域更为重视）。 \(E(\hat\beta-\beta)\rightarrow 0 \quad N \rightarrow \infty \)
** 线性回归模型估计的问题
+ 遗漏变量偏误： \[income_i=\beta_0+\beta_1 edu_i + \epsilon_i \]
+ 模型设定偏误：\[income_i=\beta_0+\beta_1 edu_i + \beta_2 age_i + \epsilon_i \]
+ 选择性偏误：高收入无应答
#+BEGIN_SRC R :results output graphics :file 3.png :width 800 :height 600
x <- runif(100,0,24)
y <- rep(0,100)
inceg <- data.frame(edu=x,income=y)
error <- rnorm(100)
inceg[inceg$edu<=12,"income"] <- 100+20*inceg[inceg$edu<=12,"edu"]
inceg[inceg$edu>12,"income"] <- 100+30*inceg[inceg$edu>12,"edu"]
inceg$income <- inceg$income + 50*error
fit0 <- lm(income~edu, data = inceg)
fit1 <- lm(income~edu, data = inceg[inceg$edu<=12,])
summary(fit0)
summary(fit1)
plot(x=inceg$edu,y=inceg$income, xlab = "education", ylab = "income", pch=20, type = "n")
abline(a=coef(fit0)[1],b=coef(fit0)[2])
abline(a=coef(fit1)[1],b=coef(fit1)[2],col="red")
points(x=inceg[inceg$edu<=12,"edu"],y=inceg[inceg$edu<=12,"income"],col="red",pch=20)
points(x=inceg[inceg$edu>12,"edu"],y=inceg[inceg$edu>12,"income"],col="blue",pch=20)
#+END_SRC
+ 完全共线性：\[entrance_i=\beta_0+\beta_1 language_i + \beta_2 math_i + \beta_3 totalscore +\epsilon_i \]
部分共线性或多重共线性条件下，回归依然是无偏和有效的，只是难以区分这些相关性较强的变量，说明缺乏数据来精准回答研究问题。
+ 协变量内生：
  - 制度与行为
  - 内生性会导致回归系数是有偏的，并且是不一致的，即增加样本量也无济于事。
  - 通过研究设计来解决内生性问题：实验法、工具变量回归、回归断点设计、自然实验等。
+ 异方差：
  - 可以采用残差图来识别异方差
#+BEGIN_SRC R :results output graphics :file 4.png :width 800 :height 600
x <- runif(1000,1,100)
error <- rnorm(1000,mean=0,sd=1*x)
y <- 10+ 3*x +error
plot(x,y)
fit0 <- lm(y~x)
abline(a=coef(fit0)[1],b=coef(fit0)[2])
#+END_SRC

+ 序列相关：时间或空间上相关. 

+ 非正态：误差不服从正态分布，即随机过程非正态。 \(credit cards =\beta_0+\beta_1 income + \epsilon \) 
** 误差方差与多元正态分布
+ 每个观测都包含系统项（\(x_i \beta\)）和随机项 \(\epsilon_i \)
+ n维向量 \(\boldsymbol{\epsilon}\)服从多元正态分布： \(\boldsymbol{\epsilon}\sim \boldsymbol{MVN(0,\Sigma)}\)
\begin{equation*}
\begin{bmatrix}
X_1 \\
X_2
\end{bmatrix}
= MVN(
\begin{bmatrix}
\mu_1 \\
\mu_2
\end{bmatrix}
,
\begin{bmatrix}
\sigma_1^2 &\sigma_{1,2} \\
\sigma_{1,2} &\sigma_2^2 
\end{bmatrix}
)
\end{equation*}
#+BEGIN_SRC R :results output graphics :file 5.png :width 600 :height 600
library (intoo)
library (bivariate)
library (MASS)
par(mfrow=c(2,2))
f = nbvpdf (0, 0, 1, 1, 0)
plot(f,T)
plot(f)
f = nbvpdf (0, 0, 1, 1, 0.8)
plot(f,T)
plot(f)
par(mfrow=c(1,1))
#+END_SRC 

** 回归的假定与高斯-马尔科夫定理
| 假定                 | 表达式                                                 | 假设不成立                    |
|----------------------+--------------------------------------------------------+-------------------------------|
| 1 无完全共线性       | rank(X)=k,k<n                                          | 无法识别回归系数              |
| 2 X外生              | E(X\epsilon )=0                                        | 有偏，且不随N增加而改善       |
| 3 误差项零均值       | E(\epsilon)=0                                          | 有偏，且不随N增加而改善       |
| 4 无序列相关         | \(E(\epsilon_{i} \epsilon_{j})=0, i\neq j \)        | 无偏但无效，标准误不正确      |
| 5 同方差             | \(E(\epsilon^{'} \epsilon)=\sigma^{2}\boldsymbol{I} \) | 无偏但无效，标准误不正确      |
| 6 误差项服从正态分布 | \(\epsilon\sim N(0,\sigma^{2})\)                       | 标准误不正确，但随N增加而改善 |
+ 如果假定1-5都成立，则最小二乘法的估计量是最优线性无偏估计量（best linear unbiased estimator, BLUE）
+ 如果假定6也成立，则为最小方差无偏的，即在所有线性和非线性估计量中方差最小。
** 回归系数方差的估计
+ 回归系数的协方差矩阵
\[Var(\boldsymbol{\hat \beta})=\boldsymbol{\hat \Sigma_{\beta}}=E[(\boldsymbol{\hat \beta - \beta})(\boldsymbol{\hat \beta - \beta})^{'}]=\sigma_{\epsilon}^2 (\boldsymbol{X^{'}X})^{-1}\]
+ 回归系数的分布
\[\boldsymbol{\hat \beta}\sim MVN(\boldsymbol{\beta},\sigma_{\epsilon}^2 (\boldsymbol{X^{'}X})^{-1})\]
+ 回归系数的标准误
\[se(\boldsymbol{\hat \beta})=\sqrt{diag(\sigma_{\epsilon}^2 (\boldsymbol{X^{'}X})^{-1})}\]
+ 可以通过t检验对回归系数进行显著性检验，如果系数的估计值与0的距离大于2个标准差，那么它在统计上就是显著的
* 线性回归推断示例
:PROPERTIES:
:header-args: :results output :exports both :session inference
:END:
** 例子：职业声望和收入
+ 变量：职业声望、收入（男性平均）、职业类型（蓝领、白领、专家）
#+BEGIN_SRC R :results output graphics :file 6.png :width 800 :height 600
library(car)
data(Duncan)
par(cex.lab=1.5,mgp=c(2.5,0.8,0),mfrow=c(1,1),family="STFangsong")

plot(x=Duncan$prestige,y=Duncan$income, xlab = "职业声望", ylab = "收入", pch=20, type = "n")
points(x=Duncan[Duncan$type=="bc","prestige"],y=Duncan[Duncan$type=="bc","income"],col="blue",pch=20)
text(x=Duncan[Duncan$type=="bc","prestige"],y=Duncan[Duncan$type=="bc","income"]-2,labels=rownames(Duncan[Duncan$type=="bc",]),col="blue")
points(x=Duncan[Duncan$type=="wc","prestige"],y=Duncan[Duncan$type=="wc","income"],col="darkgreen",pch=20)
text(x=Duncan[Duncan$type=="wc","prestige"],y=Duncan[Duncan$type=="wc","income"]-2,labels=rownames(Duncan[Duncan$type=="wc",]),col="darkgreen")
points(x=Duncan[Duncan$type=="prof","prestige"],y=Duncan[Duncan$type=="prof","income"],col="red",pch=20)
text(x=Duncan[Duncan$type=="prof","prestige"],y=Duncan[Duncan$type=="prof","income"]-2,labels=rownames(Duncan[Duncan$type=="prof",]),col="red")
legend(5,80,legend = c("蓝领","白领","专家"), col = c("blue","green","red"), pch=20, bty="n",cex=1.2)
#+END_SRC
+ 线性回归函数的使用
#+BEGIN_SRC R
fit <- lm(prestige~income+education,data=Duncan)
summary(fit)
#+END_SRC
+ 计算和绘制预测值的置信区间
#+BEGIN_SRC R :results output graphics :file 7.png :width 800 :height 600
xhyp <- seq(min(Duncan$income), max(Duncan$income),1)
zhyp <- rep(mean(Duncan$education), length(xhyp))
hypo <- data.frame(income=xhyp, education=zhyp)
pred <- predict(fit, newdata=hypo, interval="confidence",level=0.95)

plot(y=Duncan$prestige, x=Duncan$income, xlab = "Income", ylab = "Prestige", type="n")
lines(x=xhyp, y=pred[,1])
lines(x=xhyp, y=pred[,2], lty="dashed")
lines(x=xhyp, y=pred[,3], lty="dashed")
#+END_SRC

* 线性回归模型设定与拟合
:PROPERTIES:
:header-args: :results output :exports both :session specification
:END:
** 模型设定
+ 观察性研究需要面对大量关于模型设定的批评，审稿和评议人会经常要求“应该控制某某变量”。
+ 遗漏变量偏误
+ 协变量变换
+ 响应变量变换
+ 诊断异方差和模型误设
+ 拟合优度检验
** 遗留变量偏误
+ 当遗漏变量效应为0，或者遗漏变量与协变量的相关系数为0时，遗漏变量不会造成回归系数估计偏误。在其他情况下，都应该尽可能纳入。
+ 如果纳入变量确实无关，会导致损失自由度和在控制无关变量后，相关协变量的变异降低，即标准误会上升。
+ 那么实证中如何决定是否纳入变量？由于我们并不知道真实的模型是什么样子，我们要通过选择不同的模型设定展现模型的稳健性，试试看多大程度的模型改变才能使得推断结果发生变化。需要的改变越大，则说明模型越稳健.值得注意的是，如果模型中存在相互抵消的偏误，增加部分遗漏变量，可能效果适得其反。
+ 我们应该剔除“处理后”变量，否则它可能会遮掩解释变量的效应。
+ 检验多个假设需要多个模型设定。
** 协变量多项式变换
+ 可以增加二次项、三次项、四次项等，但是要防止过度拟合，即样本数据与模型完全拟合，但是对于样本外数据拟合程度反而很低。
+ 多项式设定一般不超过二次项，小样本得出的多项式拟合不可靠，需要样本外数据验证。
#+BEGIN_SRC R :results output graphics :file 8.png :width 600 :height 800
# 模拟多项式
rm(list=ls())
set.seed(258)
x <- runif(10,1,10)
y <- x + rnorm(10,0,3)
xout <- runif(10,1,10)
yout <- xout + rnorm(10,0,3)

models <- c("y~x","y~x+I(x^2)","y~x+I(x^2)+I(x^3)+I(x^4)","y~x+I(x^2)+I(x^3)+I(x^4)+I(x^5)+I(x^6)+I(x^7)+I(x^8)+I(x^9)+I(x^10)")
obs <- 10
xhy <- seq(0,12,0.1)
polymord <- c(1,2,4,10)
par(mfrow=c(4,2))
for(i in 1:4) {
  polym <- polymord[i]
  fit <- lm(formula = models[i])
  modelsum <- summary(fit)
  modelinfo <- paste("Obs:", obs, "Order:", polym, "SE:", round(modelsum$sigma, digits=2), "R−Squared:", round(modelsum$r.squared, digits=2))
  plot(x=x, y=y, pch=20, main = modelinfo,xlim = c(0,12),ylim=c(-1,15))
  lines(x=xhy, y=predict(fit,newdata=data.frame(x=xhy)),col="red")
  
  pred <- predict(fit, newdata=data.frame(x=xout),se.fit = T)
  sigmaout <- sqrt(sum((yout-pred$fit)^2)/pred$df)
  rsqdout <- (cor(yout, pred$fit))^2
  modelinfo <-  paste("Obs:", obs, "Order:", polym, "SE:", round(sigmaout, digits=2), "R−Squared:", round(rsqdout, digits=2))
  plot(x=xout, y=yout, pch=20, col="blue", main = modelinfo,xlim = c(0,12),ylim=c(-1,15))
  lines(x=xhy, y=predict(fit,newdata=data.frame(x=xhy)),col="red")
}
#+END_SRC
** 变量对数变换
+ 协变量的对数变换：
\[Y=\beta_0+\beta_1 log(x_1 ) + \beta_2 X_2 + \dots + \epsilon \]
+ 响应变量的对数变换：
\[log(y)=\beta_0+\beta_1 X_1 + \beta_2 X_2 + \dots + \epsilon \]
+ 如果Y是有界的连续变量，比如落在0到1之间，那么我们需要转化后让它能够在 -\infty 和 + \infty 之间变动。
\[log(\frac{y}{1-y})=\beta_0+\beta_1 log(x_1 ) + \beta_2 X_2 + \dots + \epsilon \]
  - 注意Y不能包含0或者1，不是logit模型，是logit转换的响应变量，只是从变量变换角度得到较好的拟合效果。
  - 对于任意的\(y\in (a,b)\)，都可以转换 \(y^*=\frac{y-a}{b-a}\)，同样不能有恰好a或b的取值。
+ 这些变量变换后的模型，本质依旧是线性模型，依然可以用最小二乘估计得到无偏有效的结果。
+ 含零值协变量的对数与logit变换（Christopher Adolph）
  - 通常会直接将0先转换成一个比较小的数（0.1或者0.001等），然后再取对数，但是对小数取对数会引入非常大的偏差。
  - 如果0值占比很少，可以删除，但是需要评估删除可能对模型估计造成的影响。
  - 在对因变量变换前，要认真考虑数据的生成过程，这些0值是否意味着不一样的分布，可能要选择广义线性模型，例如泊松回归等。
  - 如果是协变量，建议采用生成两个变量：1个虚拟变量 \(D_i\) 当\(x_i >0\)为1，否则为0 ；1个对数变量当 \(x_{i}=0\) 时为0，不为0为\(log(x_i)\). 那么，此时如何解释回归系数？
\[y_i=\beta_0 + \beta_1 D_i + \beta_2 log^{'}(x_i)+\epsilon_i \] 
  - 对于logit变换，则生成三个变量：1个虚拟变量 \(D_i\) 当\(x_i >0\)为1，否则为0 ；另1个虚拟变量 \(M_i\) 当\(x_i \geqslant 1\)为1，否则为0 ；1个logit变量当 \(x_{i} = 0\) 或者 \(x_{i} = 1\) 时为0，其他正常情况下为\(logit(x_i)\). 
\[y_i=\beta_0 + \beta_1 D_i + \beta_2 M_i + \beta_3 logit^{'}(x_i)+\epsilon_i \]
 
** 变量变化后的模型解释
+ 响应变量对数化后，回归系数表示1单位X的变化相应的Y的百分比变化。
+ 协变量对数化，回归系数表示1%的X的变化相应的Y的水平变化。
+ 响应变量与协变量都对数化后，回归系数表示1%的X的变化相应的Y的百分比变化。
+ 对于多项式系数，制作\(X\)与\(\hat Y\)的变化图来展示，不应分开解释各个多项式的系数。
+ 对于交互项\(X \times Z\)，对X与Z不同组合制作\(X\)与\(\hat Y\)的变化图来展示，不应分开解释各个项的系数。
** 模型设定示例：预期寿命的影响因素
+ 数据来源：罗伯特·J.巴罗，夏威尔·萨拉-伊-马丁《经济增长》所引用的[[http://www.columbia.edu/~xs23/data/barrlee.htm][Barro-Lee数据集]]（我们只使用[[./life.csv][整理后85年数据]])
+ 135个国家的人均GDP（gdpcap）、25岁以上平均受教育年限（school）、公民自由度（civlib，由低到高1-7分）、近期战争时间比例（wartime）。
+ 原始数据提取与转换（可跳过）
#+BEGIN_SRC R :eval no
fert <- read.table("~/Downloads/barlee/fert.prn", quote="\"", comment.char="", nrows = 138)
gdpcap <- read.table("~/Downloads/barlee/gdpsh5.prn", quote="\"", comment.char="", nrows = 138)
school <- read.table("~/Downloads/barlee/human.prn", quote="\"", comment.char="", nrows = 138)
politics <- read.table("~/Downloads/barlee/pinstab.prn", quote="\"", comment.char="", nrows = 138)
ctycode <- read.table("~/Downloads/barlee/cty.prn", quote="\"", comment.char="", nrows = 138)

life <- data.frame(lifeexp=fert$V18, gdpcap=gdpcap$V8, school=school$V6, civlib=politics$V15, wartime=politics$V6)
write.csv(life, file = "~/downloads/barlee/life.csv")

#+END_SRC
+ 先来一个简单的回归，只有教育系数显著，是否符合你的预期？会不会模型设定错误？
#+BEGIN_SRC R
life <- read.csv(file = "~/downloads/barlee/life.csv")
life <- na.omit(life)
fit <- lm(formula = lifeexp ~ gdpcap + school + civlib + wartime,data = life)
summary(fit)
#+END_SRC
+ 我们所看到的效应关系是真实的吗？三个途径去验证
  - 标准误和相关检验：t检验和F检验（见回归输出结果） 
  - 残差的模式
残差的理想模式：
#+BEGIN_SRC R :results output graphics :file 9.png :width 600 :height 400
x <- runif(1000,1,100)
error <- rnorm(1000)
y <- 10+ 3*x +error
fit0 <- lm(y~x)
plot(x=x,y=fit0$residuals)
#+END_SRC
存在异方差时的模式：
#+BEGIN_SRC R :results output graphics :file 10.png :width 600 :height 400
x <- runif(1000,1,100)
error <- rnorm(1000,mean=0,sd=1*x)
y <- 10+ 3*x +error
fit0 <- lm(y~x)
plot(x=x,y=fit0$residuals)
#+END_SRC
  - 存在离群值
** 加权最小二乘法
+ 存在异方差，则具有较高误差方差的观测含有较少的信息，而具有较低误差方差的观测含有较多的信息。
+ 如果我们能在估计中给予低误差方差观察较高权重，那么能得到更有效的估计。那么相应的最小化误差平方和也变为最小化 *加权误差平方和* 。
\[\sum^{n}_{i=1} w_i \epsilon_{i}^{2}=\boldsymbol{\epsilon^{'}W\epsilon}\]
+ 回归系数加权最小二乘估计：
\[\boldsymbol{\hat \beta}_{WLS}=(\boldsymbol{X^{'}WX})^{-1}\boldsymbol{X^{'}Wy}\]
+ 上式其中W为对角线为权重的对角阵，每个权重应该与每个y观测的标准差成反比，即
\[\epsilon_i\sim N(0,\sigma^2_i )\quad \sigma^2_i = 1/w^2_i \]
+ 如果我们通过样本性质能够确定权重，lm()函数中可以通过weights参数设定权重。
+ 如果不知道权重，可以利用残差估计权重（残差平方对自变量回归的拟合值的倒数），即可行广义最小二乘法。
+ 通过该方法获取的标准误，即为怀特标准误、稳健标准误、三明治标准误、异方差一致标准误等。
#+BEGIN_SRC R
library(lmtest); library(car)
vc <- hccm(fit, type = "hc1")                
se.corrected <- sqrt(diag(vc))
coeftest(fit, vcov=vc)
#+END_SRC
** 示例的残差图
#+BEGIN_SRC R :results output graphics :file 11.png :width 600 :height 400
plot(fit$fitted.values,fit$residuals, main="life expectancy against fitted Y")
#+END_SRC
+ 有异方差问题吗？还有什么问题？
+ 残差与拟合值相关，意味着什么？
+ 分别检查残差与各个协变量的关系
  - 残差与公民自由度的关系
#+BEGIN_SRC R :results output graphics :file 12.png :width 600 :height 400
plot(life$civlib,fit$residuals)
#+END_SRC
  - 残差与战时比例的关系
#+BEGIN_SRC R :results output graphics :file 13.png :width 600 :height 400
plot(life$wartime,fit$residuals)
#+END_SRC
  - 残差与教育的关系
#+BEGIN_SRC R :results output graphics :file 14.png :width 600 :height 400
plot(life$school,fit$residuals)
#+END_SRC
  - 残差与GDP的关系
#+BEGIN_SRC R :results output graphics :file 15.png :width 600 :height 400
plot(life$gdpcap,fit$residuals)
#+END_SRC
** 示例修正模型设定
+ 公民自由度、战时比例与残差似乎没有明显模式，而教育和GDP和残差有明显的非线性相关关系。
+ 残差中的模式意味着模型设定错误。
+ 如果看到有曲线相关关系，可以考虑添加二次项或进行对话变换。
+ 重新设定模型，将教育和GDP变换为对数项。
#+BEGIN_SRC R
fit <- lm(formula = lifeexp ~ I(log(gdpcap)) + I(log(school)) + civlib + wartime, data=life)
summary(fit)
#+END_SRC
+ 再观察残差图
#+BEGIN_SRC R :results output graphics :file 16.png :width 600 :height 400
plot(fit$fitted.values,fit$residuals, main="life expectancy against fitted Y")
#+END_SRC
 - 残差与公民自由度的关系
#+BEGIN_SRC R :results output graphics :file 17.png :width 600 :height 400
plot(life$civlib,fit$residuals)
#+END_SRC
  - 残差与战时比例的关系
#+BEGIN_SRC R :results output graphics :file 18.png :width 600 :height 400
plot(life$wartime,fit$residuals)
#+END_SRC
  - 残差与教育的关系
#+BEGIN_SRC R :results output graphics :file 19.png :width 600 :height 400
plot(life$school,fit$residuals)
#+END_SRC
  - 残差与GDP的关系
#+BEGIN_SRC R :results output graphics :file 20.png :width 600 :height 400
plot(life$gdpcap,fit$residuals)
#+END_SRC
+ 观察残差图，可以看出相关模式已经消失了，但是还有异方差的可能（喇叭形）
** 比较稳健性标准误
#+BEGIN_SRC R :results output drawer :exports results
library(orgutils)
fitsum <- summary(fit)
vc <- hccm(fit, type = "hc1") 
fitout <- data.frame(est=fitsum$coefficients[,1], se=fitsum$coefficients[,2], robust_se=sqrt(diag(vc)))
toOrg(round(fitout,digits=2))
#+END_SRC

** 模型的拟合优度
+ 模型解释力的评价
  - R方
  - 回归标准误
  - 样本外检验
  - 交叉验证
** 关于\(R^2\) from Gary King ([[https://gking.harvard.edu/files/abs/mist-abs.shtml]["How not to lie with statistics"]])
+ \(R^2\)展示与一个没有协变量的空模型相比，模型协变量所能解释的变异比例。
+ \(R^2\)间接报告了观测点在回归线附近的散布情况（\(\hat \sigma^2\)直接报告）
+ \(R^2\)只能在具有相同观测和响应变量的模型间进行比较。
+ 不应追求最大化 \(R^2\) ，只要增加协变量，一定会变大。
+ 最有用的模型很少是 \(R^2\) 最大的那个。
+ \(R^2\) 不是估计量，不存在显著或不显著的问题。
** 回归标准误 
+ \(\hat \sigma^2\)反映拟合值与真实值之间的平均差距，并且它与y的单位尺度是相同的，非常容易解释。
+ \(\hat \sigma^2\)越小，说明预测效果越好，\(\hat y\)越接近真实值。
| 协变量                                 | \(R^2\) | \(\hat{\sigma}\) |
|----------------------------------------+------+--------------|
| GDP, School, Civlib, Wartime           | 0.75 |         5.43 |
| log(GDP), log(School), Civlib, Wartime | 0.88 | 3.63         |
+ 相同的数据，相同的响应变量
+ 每个值是什么含义？哪个模型好一些？
** 样本外拟合优度
+ 假设我们用CGSS2010的数据建立了某个模型，那么我们可能想知道这个模型来预测CGSS2015的数据效果如何？
+ 如果我们用模型拟合样本外数据和训练样本同样好，那么我们更有信心相信我们找到了真实的模型。
+ 样本外检验步骤：
  1. 采用训练样本拟合模型，获取回归系数 \(\hat \beta_{training}\)
  1. 用测试样本的数据计算拟合值 \(\hat y_{test}\)
  1. 比较训练样本的拟合度（例如，\(\hat \sigma_{training}\)）与测试样本的拟合度 \(std dev(y_{test} - \hat{y}_{test}) \) ，如果两者相等则说明模型预测能力高。
** 交叉验证
+ 如果我们样本量有限，并且很难找到其他的合格样本，可以采取交叉验证。
+ 交叉验证的步骤：
  1. 将数据分成k等分，留下一份作为测试集，k-1份作为训练集。特别是Leave-one-out cross validataion (LOOCV) 留一法是比较常用的技术，即将样本量为n的样本分成n等分，只留1个观测作为测试集。
  1. 采用训练集来进行回归，获取回归系数。
  1. 利用测试集和回归系数来后去测试集预测值
  1. 比较测试集预测值与真实值，计算平均预测误差，即由预测值与真实值获取的标准差。
  1. 重复1-4步 k 次，计算平均预测误差平方的均值，再取平方根，即得到了 k重交叉验证的预测误差。
#+BEGIN_SRC R
library(boot)
# 注意要采用广义线性回归函数
fitglm <- glm(lifeexp~gdpcap+school+civlib+wartime, data=life)
# 5重交叉验证
cv.err <- cv.glm(life,fitglm,K=5)
# 报告交叉验证的预测误差：第1个是原始值，第2个是调整值（与留一法比较）
cv.err$delta
#+END_SRC
| 协变量                                 |  \(R^2\) | \(\hat{\sigma}\) | 5重交叉验证误差 |
|----------------------------------------+------+--------------+-----------------|
| GDP, School, Civlib, Wartime           | 0.75 |         5.43 | 32.3            |
| log(GDP), log(School), Civlib, Wartime | 0.88 |         3.63 |     13.8        |
+ CV预测误差一般比回归标准误要高，为什么？
+ 模型设定正确与否远比正确预测更重要，为什么？失去32年的预期寿命 vs. 失去14年预期寿命哪个更严重？
** 进一步改进模型
#+BEGIN_SRC R
fit <- lm(formula = lifeexp ~ I(log(gdpcap)) + I(log(school)) + I(log(civlib)) + wartime + I(wartime^2), data=life)
summary(fit)
fitglm <- glm(lifeexp~ I(log(gdpcap)) + I(log(school)) + I(log(civlib)) + wartime + I(wartime^2), data=life)
cv.err <- cv.glm(life,fitglm,K=5)
cv.err$delta
#+END_SRC
| 协变量                                                    | \(R^2\) | \(\hat{\sigma}\) | 5重交叉验证误差 |
|-----------------------------------------------------------+---------+------------------+-----------------|
| GDP, School, Civlib, Wartime                              |    0.75 |             5.43 |            32.3 |
| log(GDP), log(School), Civlib, Wartime                    |    0.88 |             3.63 |            13.8 |
| log(GDP), log(School),log(Civlib), Wartime, \(Wartime^2\) |    0.90 |             3.48 |            12.6 |
* 离群值的检验原理
:PROPERTIES:
:header-args: :results output :exports both :session robust
:END:
** 离群值
+ 先看一个假想的例子，我们从真实模型 \(y_i=x_i+\epsilon_i \quad \epsilon \sim N(0,1)\)中抽取10个观测，进行回归，然后添加一个离群点（10, 0）后再回归，观察离群点对回归线的影响。
#+BEGIN_SRC R :results output graphics :file outlier1.png :width 600 :height 400
set.seed(1234)
x <- runif(10,1,8)
y <- x + rnorm(10)
plot(x,y)
fit <- lm(y~x)
summary(fit)
# 添加一个离群值
xot <- c(x,10)
yot <- c(y,0)
fitot <- lm(yot~xot)
summary(fitot)
plot(x,y,xlim = c(0,11))
abline(a=coef(fit)[1],b=coef(fit)[2])
abline(a=coef(fitot)[1],b=coef(fitot)[2],col="red")
points(x=10,y=0,col="red")
#+END_SRC
+ 我们可以看到在离群值存在的情况下，不仅回归系数会变小，而且显著性水平也会下降。
** 离群值的来源
+ 离群值是来自于其他分布的观测
+ 编码错误，数据输入错误
+ 可能是遗留控制变量造成的
#+BEGIN_SRC R
z <- c(rep(0,10),1)
fitaddz <- lm(yot~xot+z)
summary(fitaddz)
#+END_SRC
+ 可能是一个正常的异乎寻常的事件（黑天鹅）
+ 在多元统计分析中，很难确定是否为离群值
+ 可以通过杠杆值（leverage）和残差差异（discrepancy）来衡量一个观测对回归线的影响（influence）
** 杠杆值
+ 二维情形，自变量\(X_i\)越极端，则杠杆值越大。
+ 多维情形，采用帽子矩阵衡量\(X_i\)与\(\bar X_i\)的距离。
\begin{array}
\hat \beta &= &(X^{'}X)^{-1}X^{'}y \\
\hat y &= &X(X^{'}X)^{-1}X^{'}y \\
\hat y &= & Hy \\
H &= &X(X^{'}X)^{-1}X^{'}
\end{array}
+ 帽子矩阵是因为它能将\(y\)变成\(\hat y\)，其对角线元素\(h_i\)与\(X_i\)和\(\bar X_i\)的距离成正比。
+ 一般将\(h_i\)除以其平均值，以方便解释，即每个观测的杠杆值比平均值高多少倍。
+ 经验上如果标准化后的\(h_i\)大于2或3，那么就是比较高的杠杆值。
#+BEGIN_SRC R
hatvalues(fitot)/mean(hatvalues(fitot))
#+END_SRC
** 残差差异
+ 残差能够揭示每个观测的离群程度，但是具有高影响力的观测能够降低它的残差，为什么？
+ 首先需要纠正杠杆的影响，通过用帽子矩阵标准化残差
\[\hat \epsilon^{standard}_i = \frac{\hat \epsilon_i}{\sqrt{\Sigma_i \hat \epsilon^2_i / (n-k-1)}\sqrt{1-h_i}}\]
+ 现在标准化残差是以标准差为单位来衡量的，如果大于2，即为5%的可能性出现（小概率事件）。
+ 其次需要纠正离群值本身对残差差异的影响，可以将这个离群值排除出去，再进行回归，然后计算其标准化残差，即学生化残差。
\[\hat \epsilon^{studentized}_i = \frac{\hat \epsilon_i}{\sqrt{\Sigma_{~i} \hat \epsilon^2_{~i} / (n-k-1)}\sqrt{1-h_i}}\]
#+BEGIN_SRC R
rstudent(fitot)
#+END_SRC
+ 绘制离群值影响图
#+BEGIN_SRC R :results output graphics :file outlier2.png :width 600 :height 400
par(mfrow=c(1,2))
hatstd <- hatvalues(fitot)/mean(hatvalues(fitot))
rstd <- rstudent(fitot)
plot(hatstd, rstd, xlab="standardized hat values",ylab="studentized residuals" )
library(car)
influencePlot(fitot)
#+END_SRC
+ 对于离群值应该尽量寻求用模型去解释，谨慎考虑剔除。
* 以后整理                                                         :noexport:
+ 文献来源：[[https://www.sscnet.ucla.edu/polisci/faculty/ross/papers/articles/doesoil.pdf][Ross (2001) “Does Oil Hinder Democracy?" World Politics 53:3, April 2001]].
+ 数据：
### 统计推断
 残差 $r_i=y_i-X_i\hat \beta$是实际值与拟合值之差

 残差标准差 $\hat \sigma=\sqrt{\sum_{i=1}^{n}r_i^2/(n-k)}$衡量残差的大小，也衡量实际观察值与模型预测值之间的平均距离

 R方用来总结模型的拟合优度， $R^2=1-\hat \sigma^2/s_y^2$表示模型中因变量的变异中由自变量所解释的比例，其中 $s_y$为因变量的标准差

 统计显著性：

 残差标准差中的不确定性：模型中，估计的残差方差 $\hat \sigma^2$的抽样分布均值为 $\sigma^2$，与自由度为 $n-k$的 $\chi^2$分布成比例
---
### 图形展示
 展示一条回归线
```{r echo=T,tidy=F, eval=F}
fit.2 <- lm (kid_score ~ mom_iq)
plot (mom_iq, kid_score, xlab="Mother IQ score", ylab="Child test score")
curve (coef(fit.2)[1] + coef(fit.2)[2]*x, add=TRUE)
```
 展示两条回归线
```{r echo=T,tidy=F, eval=F}
fit.3 <- lm (kid_score ~ mom_hs + mom_iq)
colors <- ifelse (mom_hs==1, "black", "gray")
plot (mom_iq, kid_score, xlab="Mother IQ score", ylab="Child test score", col=colors, pch=20)
curve (cbind (1, 1, x) %*% coef(fit.3), add=TRUE, col="black")
curve (cbind (1, 0, x) %*% coef(fit.3), add=TRUE, col="gray")
```
---
### 图形展示
 带交互项的模型
```{r echo=T,tidy=F, eval=F}
fit.4 <- lm (kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq)
colors <- ifelse (mom_hs==1, "black", "gray")
plot (mom_iq, kid_score, xlab="Mother IQ score", ylab="Child test score", col=colors, pch=20)
curve (cbind (1, 1, x, 1*x) %*% coef(fit.4), add=TRUE, col="black")
curve (cbind (1, 0, x, 0*x) %*% coef(fit.4), add=TRUE, col="gray")
```
 拟合模型的不确定性
```{r echo=T,eval=F}
fit.2 <- lm (kid_score ~ mom_iq)
fit.2.sim <- sim (fit.2)
plot (mom_iq, kid_score, xlab="Mother IQ score", ylab="Child test score", pch=20)
for (i in 1:10){
  curve (fit.2.sim@coef[i,1] + fit.2.sim@coef[i,2]*x, add=TRUE,col="gray")
}
curve (coef(fit.2)[1] + coef(fit.2)[2]*x, add=TRUE, col="red")
```
---
### 图形展示
 分图展示每个输入变量
```{r echo=T,eval=F}
fit.3 <- lm (kid_score ~ mom_hs + mom_iq)
beta.hat <- coef (fit.3)
beta.sim <- sim (fit.3)@coef
par (mfrow=c(1,2))
plot (mom_iq, kid_score, xlab="Mother IQ score", ylab="Child test score")
for (i in 1:10){
  curve (cbind (1, mean(mom_hs), x) %*% beta.sim[i,], lwd=.5, col="gray",
         add=TRUE)
}
curve (cbind (1, mean(mom_hs), x) %*% beta.hat, col="black", add=TRUE)

plot (mom_hs, kidscore, xlab="Mother completed high school", ylab="Child test score")
for (i in 1:10){
  curve (cbind (1, x, mean(mom_iq)) %*% beta.sim[i,], lwd=.5, col="gray",
         add=TRUE)
}
curve (cbind (1, x, mean(mom_iq)) %*% beta.hat, col="black", add=TRUE)
```
---
### 图形展示
```{r out.width='50%'}
fit.3 <- lm (kid_score ~ mom_hs + mom_iq)
beta.hat <- coef (fit.3)
beta.sim <- sim (fit.3)@coef

kidscore.jitter <- jitter(kid_score)

jitter.binary <- function(a, jitt=.05){
  ifelse (a==0, runif (length(a), 0, jitt), runif (length(a), 1-jitt, 1))
}

jitter.mom_hs <- jitter.binary(mom_hs)

par (mar=c(4,4,.1,.1))
plot (mom_iq, kid_score, xlab="Mother IQ score", ylab="Child test score", 
      pch=20, xaxt="n", yaxt="n")
axis (1, c(80,100,120,140))
axis (2, c(20,60,100,140))
for (i in 1:10){
  curve (cbind (1, mean(mom_hs), x) %*% beta.sim[i,], lwd=.5, col="gray",
         add=TRUE)
}
curve (cbind (1, mean(mom_hs), x) %*% beta.hat, col="black", add=TRUE)

plot (jitter.mom_hs, kidscore.jitter, xlab="Mother completed high school",
      ylab="Child test score", pch=20, xaxt="n", yaxt="n")
axis (1, seq(0,1))
axis (2, c(0,50,100,150))
for (i in 1:10){
  curve (cbind (1, x, mean(mom_iq)) %*% beta.sim[i,], lwd=.5, col="gray",
         add=TRUE)
}
curve (cbind (1, x, mean(mom_iq)) %*% beta.hat, col="black", add=TRUE)
```
---

### 假定与诊断
 回归模型的假定
  + 效度：你所用的数据应能准确反映你的研究问题，包括准确测量因变量、纳入所有相关的预测变量、样本数据应能推广到所有的研究对象。但是实践中往往很难满足。例如，收入变量不能用于反映总资产的情况，测验分数也不能完全反映小孩的认知能力，采用心脏病高患病风险人群样本推断健康人群中锻炼与饮食对心脏病发病率影响。明确目标，不忘初心！
  
  + 线性假定：回归模型的确定性部分是预测变量的线性函数 $y=\beta_1x_1+\beta_2x_2+\cdots$，但要注意是线性于参数，输入变量可以进行变换
  
  + 误差独立：随机抽样和零条件均值 $E(\mu|x)=0$
  
  + 同方差性：误差具有相等的方差 $Var(\mu|x)=\sigma^2$，否则要采用加权最小二乘法，但即使违背，问题不严重
  
  + 正态性：误差独立于预测变量，服从于均值为零和方差为 $\sigma^2$的正态分布，不太重要

* 回归模型诊断的常用方法
:PROPERTIES:
:header-args: :results output :exports both :session autocheck
:END:
** plot函数自动绘制诊断图
+ 一般有4张诊断图
  1. 线性假定：残差与拟合值没有系统关联
  1. 正态性：正态Q-Q图是与理论正态分布相比，标准化残差的概率图，应落在呈45度角的直线上
  1. 同方差性：位置尺度图水平线周围的点应该随机分布
  1. 离群点、高杠杆点和强影响点：残差杠杆图采用cook距离来识别对模型参数的估计产生过大影响（高杠杆值）的观测点，一般Cook距离大于 $4/(n-k-1)$，则表明是强影响点
#+BEGIN_SRC R :results output graphics :file check1.png :width 600 :height 400
fit1 <- lm(weight ~ height, data=women)
par(mfrow=c(2,2))
plot(fit1)
#+END_SRC
+ 剔除离群值
#+BEGIN_SRC R :results output graphics :file check2.png :width 600 :height 400
fit2 <- lm(weight ~ height + I(height^2), data = women[-c(15),])
par(mfrow=c(2,2))
plot(fit2)
#+END_SRC

** 回归模型诊断的其他常用方法
+ 线性：成分残差图 $\epsilon_i+(\hat \beta_0+\hat \beta_1X_{1i}+\cdots+\hat \beta_k X_{ki}) \ vs.\ X_i$  
#+BEGIN_SRC R :results output graphics :file check3.png :width 600 :height 400
library(car)
states <- as.data.frame(state.x77[,c("Murder", "Population", "Illiteracy", "Income", "Frost")])
fit <- lm(Murder ~ Population + Illiteracy + Income + Frost, data=states)
crPlots(fit)
#+END_SRC
如果成分残差图存在非线性，需要添加二次项，对变量进行变换，或者采用其他非线性回归模型
+ 正态性：学生化残差的Q-Q图
#+BEGIN_SRC R :results output graphics :file check4.png :width 600 :height 400
qqPlot(fit)
#+END_SRC
+ 同方差性：计分检验与分布水平图
 计分检验原假设为误差方差不变，若检验显著则存在异方差
#+BEGIN_SRC R :results output graphics :file check5.png :width 600 :height 400
ncvTest(fit)
spreadLevelPlot(fit)
#+END_SRC
+ 误差的独立性：Durbin-Watson检验
#+BEGIN_SRC R
durbinWatsonTest(fit)
#+END_SRC
+ 多重共线性：如果多个自变量之间相关性较强，系数方差会过大；联合检验显著，而单个自变量系数不显著。可以用统计量VIF（variance inflation factor）方差膨胀因子进行检测。一般 $\sqrt{vif} >2$ 就表示存在多重共线性问题
#+BEGIN_SRC R
vif(fit)
sqrt(vif(fit)) > 2
#+END_SRC

** 预测性回归模型的构建原理
1. 纳入所有重要的预测变量
1. 必要时可对变量进行变换或者对多个变量进行综合生成单个预测变量
1. 如果变量的主效应较大，考虑添加交互项
1. 根据回归系数的显著性和预期符号对预测变量进行取舍
  + 统计不显著，与预期符号相同，一般保留在模型中  
  + 统计不显著，与预期符号相反，考虑删除
  + 统计显著，与预期符号相反，琢磨是否有这种可能性，收集潜在变量的数据，并纳入模型
  + 统计显著，与预期符号相同，保留
解释性回归模型在构建中要更重视研究问题的本质和变量在理论上的重要性，采用手动选择变量构建模型，较少自动选择变量（逐步回归等）。

** 模型比较
 + 嵌套模型的比较: 
#+BEGIN_SRC R
fit1 <- lm(Murder ~ Population + Illiteracy + Income + Frost, data=states)
fit2 <- lm(Murder ~ Population + Illiteracy, data=states)
anova(fit1, fit2)
#+END_SRC
 + 更一般的模型比较：
  - AIC（Akaike Information Criterion, 赤池信息准则）：来自信息论， $AIC = -2 ( ln ( likelihood )) + 2 K$ ，其中likelihood为给定模型的条件下数据的概率，k为参数个数。
  - 一般优先选择AIC值较小的模型，即用较少的参数获得足够拟合度。
#+BEGIN_SRC R
AIC(fit1,fit2)
#+END_SRC


